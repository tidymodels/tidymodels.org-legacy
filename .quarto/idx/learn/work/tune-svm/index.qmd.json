{"title":"Model tuning via grid search","markdown":{"yaml":{"title":"Model tuning via grid search","categories":["model tuning","SVMs"],"type":"learn-subsection","weight":1,"description":"Choose hyperparameters for a model by training on a grid of many possible parameter values.\n","toc":true,"toc-depth":2,"include-after-body":"../../../resources.html"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\n```\n  \n```{r}\n#| label: \"load\"\n#| include: false\nlibrary(tidymodels)\nlibrary(mlbench)\nlibrary(kernlab)\nlibrary(doMC)\nregisterDoMC(cores = parallel::detectCores())\n\npkgs <- c(\"tidymodels\", \"mlbench\", \"kernlab\")\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n\n`r article_req_pkgs(pkgs)`\n\nThis article demonstrates how to tune a model using grid search. Many models have **hyperparameters** that can't be learned directly from a single data set when training the model. Instead, we can train many models in a grid of possible hyperparameter values and see which ones turn out best. \n\n## Example data\n\nTo demonstrate model tuning, we'll use the Ionosphere data in the mlbench package:\n\n```{r}\n#| label: \"load-data\"\nlibrary(tidymodels)\nlibrary(mlbench)\ndata(Ionosphere)\n```\n\nFrom `?Ionosphere`:\n\n> This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"bad\" returns are those that do not; their signals pass through the ionosphere.\n\n> Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal. See cited below for more details.\n\nThere are 43 predictors and a factor outcome. Two of the predictors are factors (`V1` and `V2`) and the rest are numeric variables that have been scaled to a range of -1 to 1. Note that the two factor predictors have sparse distributions:\n\n```{r}\n#| label: \"factor-pred\"\ntable(Ionosphere$V1)\ntable(Ionosphere$V2)\n```\n\nThere's no point of putting `V2` into any model since is is a zero-variance predictor. `V1` is not but it _could_ be if the resampling process ends up sampling all of the same value. Is this an issue? It might be since the standard R formula infrastructure fails when there is only a single observed value:\n\n```{r}\n#| label: \"glm-fail\"\n#| error: false\n#| eval: false\nglm(Class ~ ., data = Ionosphere, family = binomial)\n\n# Surprisingly, this doesn't help: \n\nglm(Class ~ . - V2, data = Ionosphere, family = binomial)\n```\n\nLet's remove these two problematic variables:\n\n```{r}\n#| label: \"ion-rm\"\nIonosphere <- Ionosphere %>% select(-V1, -V2)\n```\n\n## Inputs for the search\n\nTo demonstrate, we'll fit a radial basis function support vector machine to these data and tune the SVM cost parameter and the $\\sigma$ parameter in the kernel function:\n\n```{r}\n#| label: \"svm-mod\"\nsvm_mod <-\n  svm_rbf(cost = tune(), rbf_sigma = tune()) %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"kernlab\")\n```\n\nIn this article, tuning will be demonstrated in two ways, using:\n\n- a standard R formula, and \n- a recipe.\n\nLet's create a simple recipe here:\n\n```{r}\n#| label: \"rec\"\niono_rec <-\n  recipe(Class ~ ., data = Ionosphere)  %>%\n  # remove any zero variance predictors\n  step_zv(all_predictors()) %>% \n  # remove any linear combinations\n  step_lincomb(all_numeric())\n```\n\nThe only other required item for tuning is a resampling strategy as defined by an rsample object. Let's demonstrate using basic bootstrapping:\n\n```{r}\n#| label: \"rs\"\nset.seed(4943)\niono_rs <- bootstraps(Ionosphere, times = 30)\n```\n\n## Optional inputs\n\nAn _optional_ step for model tuning is to specify which metrics should be computed using the out-of-sample predictions. For classification, the default is to calculate the log-likelihood statistic and overall accuracy. Instead of the defaults, the area under the ROC curve will be used. To do this, a yardstick package function can be used to create a metric set:\n\n```{r}\n#| label: \"roc\"\nroc_vals <- metric_set(roc_auc)\n```\n\nIf no grid or parameters are provided, a set of 10 hyperparameters are created using a space-filling design (via a Latin hypercube). A grid can be given in a data frame where the parameters are in columns and parameter combinations are in rows. Here, the default will be used.\n\nAlso, a control object can be passed that specifies different aspects of the search. Here, the verbose option is turned off and the option to save the out-of-sample predictions is turned on. \n\n```{r}\n#| label: \"ctrl\"\nctrl <- control_grid(verbose = FALSE, save_pred = TRUE)\n```\n\n## Executing with a formula\n\nFirst, we can use the formula interface:\n\n```{r}\n#| label: \"grid\"\n#| message: false\nset.seed(35)\nformula_res <-\n  svm_mod %>% \n  tune_grid(\n    Class ~ .,\n    resamples = iono_rs,\n    metrics = roc_vals,\n    control = ctrl\n  )\nformula_res\n```\n\nThe `.metrics` column contains tibbles of the performance metrics for each tuning parameter combination:\n\n```{r}\n#| label: \"raw-metrics\"\nformula_res %>% \n  select(.metrics) %>% \n  slice(1) %>% \n  pull(1)\n```\n\nTo get the final resampling estimates, the `collect_metrics()` function can be used on the grid object:\n\n```{r}\n#| label: \"metric-estimates\"\nestimates <- collect_metrics(formula_res)\nestimates\n```\n\nThe top combinations are:\n\n```{r}\n#| label: \"sorted-metrics\"\nshow_best(formula_res, metric = \"roc_auc\")\n```\n\n##  Executing with a recipe\n\nNext, we can use the same syntax but pass a *recipe* in as the pre-processor argument:\n\n```{r}\n#| label: \"recipe\"\nset.seed(325)\nrecipe_res <-\n  svm_mod %>% \n  tune_grid(\n    iono_rec,\n    resamples = iono_rs,\n    metrics = roc_vals,\n    control = ctrl\n  )\nrecipe_res\n```\n\nThe best setting here is:\n\n```{r}\n#| label: \"best-rec\"\nshow_best(recipe_res, metric = \"roc_auc\")\n```\n\n## Out-of-sample predictions\n\nIf we used `save_pred = TRUE` to keep the out-of-sample predictions for each resample during tuning, we can obtain those predictions, along with the tuning parameters and resample identifier, using `collect_predictions()`:\n\n```{r}\n#| label: \"rec-preds\"\ncollect_predictions(recipe_res)\n```\n\nWe can obtain the hold-out sets for all the resamples augmented with the predictions using `augment()`, which provides opportunities for flexible visualization of model results:\n\n```{r}\n#| label: \"augment-preds\"\naugment(recipe_res) %>%\n  ggplot(aes(V3, .pred_good, color = Class)) +\n  geom_point(show.legend = FALSE) +\n  facet_wrap(~Class)\n```\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\n```\n  \n```{r}\n#| label: \"load\"\n#| include: false\nlibrary(tidymodels)\nlibrary(mlbench)\nlibrary(kernlab)\nlibrary(doMC)\nregisterDoMC(cores = parallel::detectCores())\n\npkgs <- c(\"tidymodels\", \"mlbench\", \"kernlab\")\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n## Introduction\n\n`r article_req_pkgs(pkgs)`\n\nThis article demonstrates how to tune a model using grid search. Many models have **hyperparameters** that can't be learned directly from a single data set when training the model. Instead, we can train many models in a grid of possible hyperparameter values and see which ones turn out best. \n\n## Example data\n\nTo demonstrate model tuning, we'll use the Ionosphere data in the mlbench package:\n\n```{r}\n#| label: \"load-data\"\nlibrary(tidymodels)\nlibrary(mlbench)\ndata(Ionosphere)\n```\n\nFrom `?Ionosphere`:\n\n> This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"bad\" returns are those that do not; their signals pass through the ionosphere.\n\n> Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal. See cited below for more details.\n\nThere are 43 predictors and a factor outcome. Two of the predictors are factors (`V1` and `V2`) and the rest are numeric variables that have been scaled to a range of -1 to 1. Note that the two factor predictors have sparse distributions:\n\n```{r}\n#| label: \"factor-pred\"\ntable(Ionosphere$V1)\ntable(Ionosphere$V2)\n```\n\nThere's no point of putting `V2` into any model since is is a zero-variance predictor. `V1` is not but it _could_ be if the resampling process ends up sampling all of the same value. Is this an issue? It might be since the standard R formula infrastructure fails when there is only a single observed value:\n\n```{r}\n#| label: \"glm-fail\"\n#| error: false\n#| eval: false\nglm(Class ~ ., data = Ionosphere, family = binomial)\n\n# Surprisingly, this doesn't help: \n\nglm(Class ~ . - V2, data = Ionosphere, family = binomial)\n```\n\nLet's remove these two problematic variables:\n\n```{r}\n#| label: \"ion-rm\"\nIonosphere <- Ionosphere %>% select(-V1, -V2)\n```\n\n## Inputs for the search\n\nTo demonstrate, we'll fit a radial basis function support vector machine to these data and tune the SVM cost parameter and the $\\sigma$ parameter in the kernel function:\n\n```{r}\n#| label: \"svm-mod\"\nsvm_mod <-\n  svm_rbf(cost = tune(), rbf_sigma = tune()) %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"kernlab\")\n```\n\nIn this article, tuning will be demonstrated in two ways, using:\n\n- a standard R formula, and \n- a recipe.\n\nLet's create a simple recipe here:\n\n```{r}\n#| label: \"rec\"\niono_rec <-\n  recipe(Class ~ ., data = Ionosphere)  %>%\n  # remove any zero variance predictors\n  step_zv(all_predictors()) %>% \n  # remove any linear combinations\n  step_lincomb(all_numeric())\n```\n\nThe only other required item for tuning is a resampling strategy as defined by an rsample object. Let's demonstrate using basic bootstrapping:\n\n```{r}\n#| label: \"rs\"\nset.seed(4943)\niono_rs <- bootstraps(Ionosphere, times = 30)\n```\n\n## Optional inputs\n\nAn _optional_ step for model tuning is to specify which metrics should be computed using the out-of-sample predictions. For classification, the default is to calculate the log-likelihood statistic and overall accuracy. Instead of the defaults, the area under the ROC curve will be used. To do this, a yardstick package function can be used to create a metric set:\n\n```{r}\n#| label: \"roc\"\nroc_vals <- metric_set(roc_auc)\n```\n\nIf no grid or parameters are provided, a set of 10 hyperparameters are created using a space-filling design (via a Latin hypercube). A grid can be given in a data frame where the parameters are in columns and parameter combinations are in rows. Here, the default will be used.\n\nAlso, a control object can be passed that specifies different aspects of the search. Here, the verbose option is turned off and the option to save the out-of-sample predictions is turned on. \n\n```{r}\n#| label: \"ctrl\"\nctrl <- control_grid(verbose = FALSE, save_pred = TRUE)\n```\n\n## Executing with a formula\n\nFirst, we can use the formula interface:\n\n```{r}\n#| label: \"grid\"\n#| message: false\nset.seed(35)\nformula_res <-\n  svm_mod %>% \n  tune_grid(\n    Class ~ .,\n    resamples = iono_rs,\n    metrics = roc_vals,\n    control = ctrl\n  )\nformula_res\n```\n\nThe `.metrics` column contains tibbles of the performance metrics for each tuning parameter combination:\n\n```{r}\n#| label: \"raw-metrics\"\nformula_res %>% \n  select(.metrics) %>% \n  slice(1) %>% \n  pull(1)\n```\n\nTo get the final resampling estimates, the `collect_metrics()` function can be used on the grid object:\n\n```{r}\n#| label: \"metric-estimates\"\nestimates <- collect_metrics(formula_res)\nestimates\n```\n\nThe top combinations are:\n\n```{r}\n#| label: \"sorted-metrics\"\nshow_best(formula_res, metric = \"roc_auc\")\n```\n\n##  Executing with a recipe\n\nNext, we can use the same syntax but pass a *recipe* in as the pre-processor argument:\n\n```{r}\n#| label: \"recipe\"\nset.seed(325)\nrecipe_res <-\n  svm_mod %>% \n  tune_grid(\n    iono_rec,\n    resamples = iono_rs,\n    metrics = roc_vals,\n    control = ctrl\n  )\nrecipe_res\n```\n\nThe best setting here is:\n\n```{r}\n#| label: \"best-rec\"\nshow_best(recipe_res, metric = \"roc_auc\")\n```\n\n## Out-of-sample predictions\n\nIf we used `save_pred = TRUE` to keep the out-of-sample predictions for each resample during tuning, we can obtain those predictions, along with the tuning parameters and resample identifier, using `collect_predictions()`:\n\n```{r}\n#| label: \"rec-preds\"\ncollect_predictions(recipe_res)\n```\n\nWe can obtain the hold-out sets for all the resamples augmented with the predictions using `augment()`, which provides opportunities for flexible visualization of model results:\n\n```{r}\n#| label: \"augment-preds\"\naugment(recipe_res) %>%\n  ggplot(aes(V3, .pred_good, color = Class)) +\n  geom_point(show.legend = FALSE) +\n  facet_wrap(~Class)\n```\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"include-after-body":["../../../resources.html"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","notebook-preview-download":"Download Notebook","notebook-preview-back":"Back to Article"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.92","theme":["cosmo","../../../styles.scss","../../../styles-frontpage.scss"],"quarto-required":">= 1.3.353","linestretch":1.6,"grid":{"body-width":"840px"},"title":"Model tuning via grid search","categories":["model tuning","SVMs"],"type":"learn-subsection","weight":1,"description":"Choose hyperparameters for a model by training on a grid of many possible parameter values.\n"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}