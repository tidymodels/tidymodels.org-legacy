{"title":"Creating case weights based on time","markdown":{"yaml":{"title":"Creating case weights based on time","categories":["model fitting","case weights","time series"],"type":"learn-subsection","weight":5,"description":"Create models that use coefficients, extract them from fitted models, and visualize them.\n","toc":true,"toc-depth":2,"include-after-body":"../../../resources.html"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\npkgs <- c(\"tidymodels\")\n```\n  \n```{r}\n#| label: \"load\"\n#| include: false\nlibrary(tidymodels)\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n\n`r article_req_pkgs(pkgs)`\n\nThis article demonstrates how to create and use importance weights in a predictive model. Using importance weights is a way to have our model care more about some observations than others.\n\n## Example Data\n\nTo demonstrate we will use the Chicago data from the modeldata package.\n\n```{r}\nlibrary(tidymodels)\ndata(Chicago)\n\nChicago <- Chicago %>%\n  select(ridership, date, one_of(stations))\n```\n\nFrom `?Chicago`\n\n> These data are from Kuhn and Johnson (2020) and contain an abbreviated training set for modeling the number of people (in thousands) who enter the Clark and Lake L station.\n\n> The date column corresponds to the current date. The columns with station names (Austin through California) are a sample of the columns used in the original analysis (for filesize reasons). These are 14 day lag variables (i.e. date - 14 days). There are columns related to weather and sports team schedules.\n\nFor simplicity, we have limited our view to the date and station variables.\n\n## Creating weights\n\nThis data set contains daily information from `r min(Chicago$date)` to `r max(Chicago$date)`. We will pretend that it is January 1st, 2016 and we want to predict the ridership for the remainder of 2016 using the date and station variables as predictors. Without any weighting, all the previous observations would have the same influence on the model. This may not be ideal since some observations appear a long time ago and not be as representative of the future as more recent observations. \n\nWe could just use recent observations to fit the model, ensuring that the training data stays as close to the testing data as possible. While a tempting idea, it would throw out a lot of informative data. Instead let us assign a weight to each observation, related to how long ago the observation was taken. This way we are not completely throwing away any observation; we are only giving less weight to data farther in the past. \n\nWe need to decide on a way to calculate the case weights. The main thing constraint is that the weight cannot be negative, and it would be nice if today was weighted as 1. So we need a function that is 1 when `x = 0` and decreasing otherwise. There are many kinds of functions like that, and we will be using this exponential decay function\n\n$$ weight = base ^ x $$\n\nwhere `base` is some constant and `x` is the number of days. To make sure that we select a reasonable `base`, we need to do some manual testing, starting with looking at how old the oldest observation is.\n\n```{r}\ndifftime(\"2016-01-01\", min(Chicago$date))\n```\n\nUsing this information we can visualize the weight curve, to see if we like the value of `base`.\n\n```{r}\ntibble_days <- tibble(days = 0:5457)\n\ntibble_days %>%\n  ggplot(aes(days)) +\n  geom_function(fun = ~ 0.99 ^ .x)\n```\n\nsetting `base` to 0.99 appears to be down weighted too much. Any observation more than a year old would have no influence.\n\nLet us try a few more values to find \n\n```{r}\nmap_dfr(\n  c(0.99, 0.999, 0.9999),\n  ~ tibble_days %>% mutate(base = factor(.x), value = .x ^ days)\n) %>%\n  ggplot(aes(days, value, group = base, color = base)) +\n  geom_line()\n```\n\nFrom this, we could pick something around 0.999 since it gives a better balance. Let's create a small function to help us encode this weight. \n\n```{r}\nweights_from_dates <- function(x, ref) {\n  if_else(\n    condition = x >= ref,\n    true = 1,     # <- Notice that I'm setting any future weight to 1.\n    false = 0.999 ^ as.numeric(difftime(ref, x, units = \"days\"))\n  )\n}\n```\n\nWe then modify `Chicago` to add a weight column, explicitly making it an importance weight with `importance_weight()`.\n\n```{r}\nChicago <- Chicago %>%\n  mutate(weight = weights_from_dates(date, \"2016-01-01\"),\n         weight = importance_weights(weight))\n```\n\nThis approach to creating importance weights from dates is not limited to cases where we have daily observations. You are free to create similar weights if you have gaps or repeated observations within the same day. Likewise, you don't need to use days as the unit. Seconds, weeks, or years could be used as well.\n\n## Modeling\n\nWe start by splitting up our data into a training and testing set based on the day `\"2016-01-01\"`. We added weights to the data set before splitting it so each set has weights.\n\n```{r}\nChicago_train <- Chicago %>% filter(date < \"2016-01-01\")\nChicago_test <- Chicago %>% filter(date >= \"2016-01-01\")\n```\n\nNext, we are going to create a recipe. The weights won't have any influence on the preprocessing since none of these operations are supervised and we are using importance weights.\n\n```{r}\nbase_recipe <-\n  recipe(ridership ~ ., data = Chicago_train) %>%\n  # Create date features\n  step_date(date) %>%\n  step_holiday(date, keep_original_cols = FALSE) %>%\n  # Remove any columns with a single unique value\n  step_zv(all_predictors()) %>%\n  # Normalize all the numerical features\n  step_normalize(all_numeric_predictors()) %>%\n  # Perform PCA to reduce the correlation bet the stations\n  step_pca(all_numeric_predictors(), threshold = 0.95)\n```\n\nNext we need to build the rest of the workflow. We use a linear regression specification\n\n```{r}\nlm_spec <-\n  linear_reg() %>%\n  set_engine(\"lm\")\n```\n\nand we add these together in the workflow. To activate the case weights, we use the `add_case_weights()` function to specify the name of the case weights being used.\n\n```{r}\nlm_wflow <-\n  workflow() %>% \n  add_case_weights(weight) %>%\n  add_recipe(base_recipe) %>%\n  add_model(lm_spec)\n\nlm_wflow\n```\n\nWith all that done we can fit the workflow with the usual syntax: \n\n```{r}\nlm_fit <- fit(lm_wflow, data = Chicago_train)\nlm_fit\n```\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\npkgs <- c(\"tidymodels\")\n```\n  \n```{r}\n#| label: \"load\"\n#| include: false\nlibrary(tidymodels)\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n## Introduction\n\n`r article_req_pkgs(pkgs)`\n\nThis article demonstrates how to create and use importance weights in a predictive model. Using importance weights is a way to have our model care more about some observations than others.\n\n## Example Data\n\nTo demonstrate we will use the Chicago data from the modeldata package.\n\n```{r}\nlibrary(tidymodels)\ndata(Chicago)\n\nChicago <- Chicago %>%\n  select(ridership, date, one_of(stations))\n```\n\nFrom `?Chicago`\n\n> These data are from Kuhn and Johnson (2020) and contain an abbreviated training set for modeling the number of people (in thousands) who enter the Clark and Lake L station.\n\n> The date column corresponds to the current date. The columns with station names (Austin through California) are a sample of the columns used in the original analysis (for filesize reasons). These are 14 day lag variables (i.e. date - 14 days). There are columns related to weather and sports team schedules.\n\nFor simplicity, we have limited our view to the date and station variables.\n\n## Creating weights\n\nThis data set contains daily information from `r min(Chicago$date)` to `r max(Chicago$date)`. We will pretend that it is January 1st, 2016 and we want to predict the ridership for the remainder of 2016 using the date and station variables as predictors. Without any weighting, all the previous observations would have the same influence on the model. This may not be ideal since some observations appear a long time ago and not be as representative of the future as more recent observations. \n\nWe could just use recent observations to fit the model, ensuring that the training data stays as close to the testing data as possible. While a tempting idea, it would throw out a lot of informative data. Instead let us assign a weight to each observation, related to how long ago the observation was taken. This way we are not completely throwing away any observation; we are only giving less weight to data farther in the past. \n\nWe need to decide on a way to calculate the case weights. The main thing constraint is that the weight cannot be negative, and it would be nice if today was weighted as 1. So we need a function that is 1 when `x = 0` and decreasing otherwise. There are many kinds of functions like that, and we will be using this exponential decay function\n\n$$ weight = base ^ x $$\n\nwhere `base` is some constant and `x` is the number of days. To make sure that we select a reasonable `base`, we need to do some manual testing, starting with looking at how old the oldest observation is.\n\n```{r}\ndifftime(\"2016-01-01\", min(Chicago$date))\n```\n\nUsing this information we can visualize the weight curve, to see if we like the value of `base`.\n\n```{r}\ntibble_days <- tibble(days = 0:5457)\n\ntibble_days %>%\n  ggplot(aes(days)) +\n  geom_function(fun = ~ 0.99 ^ .x)\n```\n\nsetting `base` to 0.99 appears to be down weighted too much. Any observation more than a year old would have no influence.\n\nLet us try a few more values to find \n\n```{r}\nmap_dfr(\n  c(0.99, 0.999, 0.9999),\n  ~ tibble_days %>% mutate(base = factor(.x), value = .x ^ days)\n) %>%\n  ggplot(aes(days, value, group = base, color = base)) +\n  geom_line()\n```\n\nFrom this, we could pick something around 0.999 since it gives a better balance. Let's create a small function to help us encode this weight. \n\n```{r}\nweights_from_dates <- function(x, ref) {\n  if_else(\n    condition = x >= ref,\n    true = 1,     # <- Notice that I'm setting any future weight to 1.\n    false = 0.999 ^ as.numeric(difftime(ref, x, units = \"days\"))\n  )\n}\n```\n\nWe then modify `Chicago` to add a weight column, explicitly making it an importance weight with `importance_weight()`.\n\n```{r}\nChicago <- Chicago %>%\n  mutate(weight = weights_from_dates(date, \"2016-01-01\"),\n         weight = importance_weights(weight))\n```\n\nThis approach to creating importance weights from dates is not limited to cases where we have daily observations. You are free to create similar weights if you have gaps or repeated observations within the same day. Likewise, you don't need to use days as the unit. Seconds, weeks, or years could be used as well.\n\n## Modeling\n\nWe start by splitting up our data into a training and testing set based on the day `\"2016-01-01\"`. We added weights to the data set before splitting it so each set has weights.\n\n```{r}\nChicago_train <- Chicago %>% filter(date < \"2016-01-01\")\nChicago_test <- Chicago %>% filter(date >= \"2016-01-01\")\n```\n\nNext, we are going to create a recipe. The weights won't have any influence on the preprocessing since none of these operations are supervised and we are using importance weights.\n\n```{r}\nbase_recipe <-\n  recipe(ridership ~ ., data = Chicago_train) %>%\n  # Create date features\n  step_date(date) %>%\n  step_holiday(date, keep_original_cols = FALSE) %>%\n  # Remove any columns with a single unique value\n  step_zv(all_predictors()) %>%\n  # Normalize all the numerical features\n  step_normalize(all_numeric_predictors()) %>%\n  # Perform PCA to reduce the correlation bet the stations\n  step_pca(all_numeric_predictors(), threshold = 0.95)\n```\n\nNext we need to build the rest of the workflow. We use a linear regression specification\n\n```{r}\nlm_spec <-\n  linear_reg() %>%\n  set_engine(\"lm\")\n```\n\nand we add these together in the workflow. To activate the case weights, we use the `add_case_weights()` function to specify the name of the case weights being used.\n\n```{r}\nlm_wflow <-\n  workflow() %>% \n  add_case_weights(weight) %>%\n  add_recipe(base_recipe) %>%\n  add_model(lm_spec)\n\nlm_wflow\n```\n\nWith all that done we can fit the workflow with the usual syntax: \n\n```{r}\nlm_fit <- fit(lm_wflow, data = Chicago_train)\nlm_fit\n```\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"include-after-body":["../../../resources.html"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","notebook-preview-download":"Download Notebook","notebook-preview-back":"Back to Article"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.92","theme":["cosmo","../../../styles.scss","../../../styles-frontpage.scss"],"quarto-required":">= 1.3.353","linestretch":1.6,"grid":{"body-width":"840px"},"title":"Creating case weights based on time","categories":["model fitting","case weights","time series"],"type":"learn-subsection","weight":5,"description":"Create models that use coefficients, extract them from fitted models, and visualize them.\n"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}