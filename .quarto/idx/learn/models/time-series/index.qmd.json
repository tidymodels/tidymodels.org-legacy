{"title":"Modeling time series with tidy resampling","markdown":{"yaml":{"title":"Modeling time series with tidy resampling","categories":["model fitting","time series"],"type":"learn-subsection","weight":4,"description":"Calculate performance estimates for time series forecasts using resampling.\n","toc":true,"toc-depth":2,"include-after-body":"../../../resources.html"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\n```\n\n```{r}\n#| label: \"load\"\n#| include: false\n#| message: false\n#| warning: false\nlibrary(timetk)\nlibrary(forecast)\nlibrary(tidymodels)\nlibrary(sweep)\nlibrary(zoo)\npkgs <- c(\"tidymodels\", \"timetk\", \"forecast\", \"sweep\", \"zoo\")\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n\n\n`r article_req_pkgs(pkgs)`\n\n\"[Demo Week: Tidy Forecasting with sweep](https://www.business-science.io/code-tools/2017/10/25/demo_week_sweep.html)\" is an excellent article that uses tidy methods with time series. This article uses their analysis with rsample to find performance estimates for future observations using [rolling forecast origin resampling](https://robjhyndman.com/hyndsight/crossvalidation/). \n\n## Example data\n\nThe data for this article are sales of alcoholic beverages originally from [the Federal Reserve Bank of St. Louis website](https://fred.stlouisfed.org/series/S4248SM144NCEN).\n\n```{r}\n#| label: \"read-data\"\nlibrary(tidymodels)\nlibrary(modeldata)\ndata(\"drinks\")\nglimpse(drinks)\n```\n\nEach row represents one month of sales (in millions of US dollars). \n\n## Time series resampling\n\nSuppose that we need predictions for one year ahead and our model should use the most recent data from the last 20 years. To set up this resampling scheme:\n\n```{r}\n#| label: \"rof\"\nroll_rs <- rolling_origin(\n  drinks, \n  initial = 12 * 20, \n  assess = 12,\n  cumulative = FALSE\n  )\n\nnrow(roll_rs)\n\nroll_rs\n```\n\nEach `split` element contains the information about that resample:\n\n```{r}\n#| label: \"split\"\nroll_rs$splits[[1]]\n```\n\nFor plotting, let's index each split by the first day of the assessment set:\n\n```{r}\n#| label: \"labels\"\nget_date <- function(x) {\n  min(assessment(x)$date)\n}\n\nstart_date <- map(roll_rs$splits, get_date)\nroll_rs$start_date <- do.call(\"c\", start_date)\nhead(roll_rs$start_date)\n```\n\nThis resampling scheme has `r nrow(roll_rs)` splits of the data so that there will be `r nrow(roll_rs)` ARIMA models that are fit. To create the models, we use the `auto.arima()` function from the forecast package. The rsample functions `analysis()` and `assessment()` return a data frame, so another step converts the data to a `ts` object called `mod_dat` using a function in the timetk package.\n\n```{r}\n#| label: \"model-fun\"\nlibrary(forecast)  # for `auto.arima`\nlibrary(timetk)    # for `tk_ts`\nlibrary(zoo)       # for `as.yearmon`\n\nfit_model <- function(x, ...) {\n  # suggested by Matt Dancho:\n  x %>%\n    analysis() %>%\n    # Since the first day changes over resamples, adjust it\n    # based on the first date value in the data frame \n    tk_ts(start = .$date[[1]] %>% as.yearmon(), \n          frequency = 12, \n          silent = TRUE) %>%\n    auto.arima(...)\n}\n```\n\nSave each model in a new column:\n\n```{r}\n#| label: \"model-fit\"\n#| warning: false\n#| message: false\nroll_rs$arima <- map(roll_rs$splits, fit_model)\n\n# For example:\nroll_rs$arima[[1]]\n```\n\n(There are some warnings produced by these regarding extra columns in the data that can be ignored.)\n\n## Model performance\n\nUsing the model fits, let's measure performance in two ways:\n\n * _Interpolation_ error will measure how well the model fits to the data that were used to create the model. This is most likely optimistic since no holdout method is used. \n * _Extrapolation_ or _forecast_ error evaluates the performance of the model on the data from the following year (that were not used in the model fit).\n \nIn each case, the mean absolute percent error (MAPE) is the statistic used to characterize the model fits. The interpolation error can be computed from the `Arima` object. To make things easy, let's use the sweep package's `sw_glance()` function:\n\n```{r}\n#| label: \"interp\"\nlibrary(sweep)\n\nroll_rs$interpolation <- map_dbl(\n  roll_rs$arima,\n  function(x) \n    sw_glance(x)[[\"MAPE\"]]\n  )\n\nsummary(roll_rs$interpolation)\n```\n\nFor the extrapolation error, the model and split objects are required. Using these:\n\n```{r}\n#| label: \"extrap\"\nget_extrap <- function(split, mod) {\n  n <- nrow(assessment(split))\n  # Get assessment data\n  pred_dat <- assessment(split) %>%\n    mutate(\n      pred = as.vector(forecast(mod, h = n)$mean),\n      pct_error = ( S4248SM144NCEN - pred ) / S4248SM144NCEN * 100\n    )\n  mean(abs(pred_dat$pct_error))\n}\n\nroll_rs$extrapolation <- \n  map2_dbl(roll_rs$splits, roll_rs$arima, get_extrap)\n\nsummary(roll_rs$extrapolation)\n```\n\nWhat do these error estimates look like over time?\n\n```{r}\n#| label: \"plot\"\nroll_rs %>%\n  select(interpolation, extrapolation, start_date) %>%\n  pivot_longer(cols = matches(\"ation\"), names_to = \"error\", values_to = \"MAPE\") %>%\n  ggplot(aes(x = start_date, y = MAPE, col = error)) + \n  geom_point() + \n  geom_line()\n```\n\nIt is likely that the interpolation error is an underestimate to some degree, as mentioned above. \n\nIt is also worth noting that `rolling_origin()` can be used over calendar periods, rather than just over a fixed window size. This is especially useful for irregular series where a fixed window size might not make sense because of missing data points, or because of calendar features like different months having a different number of days.\n\nThe example below demonstrates this idea by splitting `drinks` into a nested set of 26 years, and rolling over years rather than months. Note that the end result accomplishes a different task than the original example; in this new case, each slice moves forward an entire year, rather than just one month.\n\n```{r}\n#| label: \"rof-annual\"\n# The idea is to nest by the period to roll over,\n# which in this case is the year.\nroll_rs_annual <- drinks %>%\n  mutate(year = as.POSIXlt(date)$year + 1900) %>%\n  nest(data = c(date, S4248SM144NCEN)) %>%\n  rolling_origin(\n    initial = 20, \n    assess = 1, \n    cumulative = FALSE\n  )\n\nanalysis(roll_rs_annual$splits[[1]])\n```\n\nThe workflow to access these calendar slices is to use `bind_rows()` to join\neach analysis set together.\n\n```{r}\nmutate(\n  roll_rs_annual,\n  extracted_slice = map(splits, ~ bind_rows(analysis(.x)$data))\n)\n```\n\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n \n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\n```\n\n```{r}\n#| label: \"load\"\n#| include: false\n#| message: false\n#| warning: false\nlibrary(timetk)\nlibrary(forecast)\nlibrary(tidymodels)\nlibrary(sweep)\nlibrary(zoo)\npkgs <- c(\"tidymodels\", \"timetk\", \"forecast\", \"sweep\", \"zoo\")\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n\n## Introduction\n\n`r article_req_pkgs(pkgs)`\n\n\"[Demo Week: Tidy Forecasting with sweep](https://www.business-science.io/code-tools/2017/10/25/demo_week_sweep.html)\" is an excellent article that uses tidy methods with time series. This article uses their analysis with rsample to find performance estimates for future observations using [rolling forecast origin resampling](https://robjhyndman.com/hyndsight/crossvalidation/). \n\n## Example data\n\nThe data for this article are sales of alcoholic beverages originally from [the Federal Reserve Bank of St. Louis website](https://fred.stlouisfed.org/series/S4248SM144NCEN).\n\n```{r}\n#| label: \"read-data\"\nlibrary(tidymodels)\nlibrary(modeldata)\ndata(\"drinks\")\nglimpse(drinks)\n```\n\nEach row represents one month of sales (in millions of US dollars). \n\n## Time series resampling\n\nSuppose that we need predictions for one year ahead and our model should use the most recent data from the last 20 years. To set up this resampling scheme:\n\n```{r}\n#| label: \"rof\"\nroll_rs <- rolling_origin(\n  drinks, \n  initial = 12 * 20, \n  assess = 12,\n  cumulative = FALSE\n  )\n\nnrow(roll_rs)\n\nroll_rs\n```\n\nEach `split` element contains the information about that resample:\n\n```{r}\n#| label: \"split\"\nroll_rs$splits[[1]]\n```\n\nFor plotting, let's index each split by the first day of the assessment set:\n\n```{r}\n#| label: \"labels\"\nget_date <- function(x) {\n  min(assessment(x)$date)\n}\n\nstart_date <- map(roll_rs$splits, get_date)\nroll_rs$start_date <- do.call(\"c\", start_date)\nhead(roll_rs$start_date)\n```\n\nThis resampling scheme has `r nrow(roll_rs)` splits of the data so that there will be `r nrow(roll_rs)` ARIMA models that are fit. To create the models, we use the `auto.arima()` function from the forecast package. The rsample functions `analysis()` and `assessment()` return a data frame, so another step converts the data to a `ts` object called `mod_dat` using a function in the timetk package.\n\n```{r}\n#| label: \"model-fun\"\nlibrary(forecast)  # for `auto.arima`\nlibrary(timetk)    # for `tk_ts`\nlibrary(zoo)       # for `as.yearmon`\n\nfit_model <- function(x, ...) {\n  # suggested by Matt Dancho:\n  x %>%\n    analysis() %>%\n    # Since the first day changes over resamples, adjust it\n    # based on the first date value in the data frame \n    tk_ts(start = .$date[[1]] %>% as.yearmon(), \n          frequency = 12, \n          silent = TRUE) %>%\n    auto.arima(...)\n}\n```\n\nSave each model in a new column:\n\n```{r}\n#| label: \"model-fit\"\n#| warning: false\n#| message: false\nroll_rs$arima <- map(roll_rs$splits, fit_model)\n\n# For example:\nroll_rs$arima[[1]]\n```\n\n(There are some warnings produced by these regarding extra columns in the data that can be ignored.)\n\n## Model performance\n\nUsing the model fits, let's measure performance in two ways:\n\n * _Interpolation_ error will measure how well the model fits to the data that were used to create the model. This is most likely optimistic since no holdout method is used. \n * _Extrapolation_ or _forecast_ error evaluates the performance of the model on the data from the following year (that were not used in the model fit).\n \nIn each case, the mean absolute percent error (MAPE) is the statistic used to characterize the model fits. The interpolation error can be computed from the `Arima` object. To make things easy, let's use the sweep package's `sw_glance()` function:\n\n```{r}\n#| label: \"interp\"\nlibrary(sweep)\n\nroll_rs$interpolation <- map_dbl(\n  roll_rs$arima,\n  function(x) \n    sw_glance(x)[[\"MAPE\"]]\n  )\n\nsummary(roll_rs$interpolation)\n```\n\nFor the extrapolation error, the model and split objects are required. Using these:\n\n```{r}\n#| label: \"extrap\"\nget_extrap <- function(split, mod) {\n  n <- nrow(assessment(split))\n  # Get assessment data\n  pred_dat <- assessment(split) %>%\n    mutate(\n      pred = as.vector(forecast(mod, h = n)$mean),\n      pct_error = ( S4248SM144NCEN - pred ) / S4248SM144NCEN * 100\n    )\n  mean(abs(pred_dat$pct_error))\n}\n\nroll_rs$extrapolation <- \n  map2_dbl(roll_rs$splits, roll_rs$arima, get_extrap)\n\nsummary(roll_rs$extrapolation)\n```\n\nWhat do these error estimates look like over time?\n\n```{r}\n#| label: \"plot\"\nroll_rs %>%\n  select(interpolation, extrapolation, start_date) %>%\n  pivot_longer(cols = matches(\"ation\"), names_to = \"error\", values_to = \"MAPE\") %>%\n  ggplot(aes(x = start_date, y = MAPE, col = error)) + \n  geom_point() + \n  geom_line()\n```\n\nIt is likely that the interpolation error is an underestimate to some degree, as mentioned above. \n\nIt is also worth noting that `rolling_origin()` can be used over calendar periods, rather than just over a fixed window size. This is especially useful for irregular series where a fixed window size might not make sense because of missing data points, or because of calendar features like different months having a different number of days.\n\nThe example below demonstrates this idea by splitting `drinks` into a nested set of 26 years, and rolling over years rather than months. Note that the end result accomplishes a different task than the original example; in this new case, each slice moves forward an entire year, rather than just one month.\n\n```{r}\n#| label: \"rof-annual\"\n# The idea is to nest by the period to roll over,\n# which in this case is the year.\nroll_rs_annual <- drinks %>%\n  mutate(year = as.POSIXlt(date)$year + 1900) %>%\n  nest(data = c(date, S4248SM144NCEN)) %>%\n  rolling_origin(\n    initial = 20, \n    assess = 1, \n    cumulative = FALSE\n  )\n\nanalysis(roll_rs_annual$splits[[1]])\n```\n\nThe workflow to access these calendar slices is to use `bind_rows()` to join\neach analysis set together.\n\n```{r}\nmutate(\n  roll_rs_annual,\n  extracted_slice = map(splits, ~ bind_rows(analysis(.x)$data))\n)\n```\n\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"include-after-body":["../../../resources.html"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","notebook-preview-download":"Download Notebook","notebook-preview-back":"Back to Article"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.92","theme":["cosmo","../../../styles.scss","../../../styles-frontpage.scss"],"quarto-required":">= 1.3.353","linestretch":1.6,"grid":{"body-width":"840px"},"title":"Modeling time series with tidy resampling","categories":["model fitting","time series"],"type":"learn-subsection","weight":4,"description":"Calculate performance estimates for time series forecasts using resampling.\n"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}