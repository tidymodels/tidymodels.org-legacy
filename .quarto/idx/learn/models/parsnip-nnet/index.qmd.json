{"title":"Classification models using a neural network","markdown":{"yaml":{"title":"Classification models using a neural network","categories":["model fitting","torch","neural networks"],"type":"learn-subsection","weight":2,"description":"Train a classification model and evaluate its performance.\n","toc":true,"toc-depth":2,"include-after-body":"../../../resources.html"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\n```\n  \n```{r}\n#| label: \"load\"\n#| include: false\nlibrary(tidymodels)\npkgs <- c(\"tidymodels\", \"brulee\", \"AppliedPredictiveModeling\")\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n\n\n`r article_req_pkgs(pkgs)` You will also need the python torch library installed (see `?torch::install_torch()`).\n\nWe can create classification models with the tidymodels package [parsnip](https://parsnip.tidymodels.org/) to predict categorical quantities or class labels. Here, let's fit a single classification model using a neural network and evaluate using a validation set. While the [tune](https://tune.tidymodels.org/) package has functionality to also do this, the parsnip package is the center of attention in this article so that we can better understand its usage. \n\n## Fitting a neural network\n\n\nLet's fit a model to a small, two predictor classification data set. The data are in the modeldata package (part of tidymodels) and have been split into training, validation, and test data sets. In this analysis, the test set is left untouched; this article tries to emulate a good data usage methodology where the test set would only be evaluated once at the end after a variety of models have been considered. \n\n\n```{r}\n#| label: \"biv--split\"\nlibrary(AppliedPredictiveModeling)\n\nset.seed(321)\ncls_train <- quadBoundaryFunc(2000) %>% select(A = X1, B = X2, class)\ncls_val   <- quadBoundaryFunc( 500) %>% select(A = X1, B = X2, class)\ncls_test  <- quadBoundaryFunc( 500) %>% select(A = X1, B = X2, class)\n```\n\nA plot of the data shows two right-skewed predictors: \n\n```{r}\n#| label: \"biv-plot\"\n#| fig-width:  6\n#| fig-height:  6.1\nggplot(cls_train, aes(x = A, y = B, col = class)) + \n  geom_point(alpha = 1 / 4, cex = 3) + \n  coord_fixed()\n```\n\nLet's use a single hidden layer neural network to predict the outcome. To do this, we transform the predictor columns to be more symmetric (via the `step_BoxCox()` function) and on a common scale (using `step_normalize()`). We can use [recipes](https://recipes.tidymodels.org/) to do so:\n\n```{r}\n#| label: \"biv--proc\"\nbiv_rec <- \n  recipe(class ~ ., data = cls_train) %>%\n  step_normalize(all_predictors())\n```\n\nThis recipe is not directly executed; the steps will be estimated when the model is fit. \n\nWe can use the brulee package to fit a model with 5 hidden units and a 10% dropout rate, to regularize the model:\n\n```{r}\n#| label: \"biv-nnet\"\nnnet_spec <- \n  mlp(epochs = 1000, hidden_units = 10, penalty = 0.01, learn_rate = 0.1) %>% \n  set_engine(\"brulee\", validation = 0) %>% \n  set_mode(\"classification\")\n\nnnet_wflow <- \n  biv_rec %>% \n  workflow(nnet_spec)\n\nset.seed(987)\nnnet_fit <- fit(nnet_wflow, cls_train)\nnnet_fit %>% extract_fit_engine()\n```\n\n## Model performance\n\nIn parsnip, the `predict()` function can be used to characterize performance on the validation set. Since parsnip always produces tibble outputs, these can just be column bound to the original data: \n\n```{r}\n#| label: \"biv--perf\"\nval_results <- \n  cls_val %>%\n  bind_cols(\n    predict(nnet_fit, new_data = cls_val),\n    predict(nnet_fit, new_data = cls_val, type = \"prob\")\n  )\nval_results %>% slice(1:5)\n\nval_results %>% roc_auc(truth = class, .pred_Class1)\n\nval_results %>% accuracy(truth = class, .pred_class)\n\nval_results %>% conf_mat(truth = class, .pred_class)\n```\n\nLet's also create a grid to get a visual sense of the class boundary for the test set.\n\n```{r}\n#| label: \"biv-boundary\"\n#| fig-width:  6\n#| fig-height:  6.1\na_rng <- range(cls_train$A)\nb_rng <- range(cls_train$B)\nx_grid <-\n  expand.grid(A = seq(a_rng[1], a_rng[2], length.out = 100),\n              B = seq(b_rng[1], b_rng[2], length.out = 100))\n\n\n# Make predictions using the transformed predictors but \n# attach them to the predictors in the original units: \nx_grid <- \n  x_grid %>% \n  bind_cols(predict(nnet_fit, x_grid, type = \"prob\"))\n\nggplot(x_grid, aes(x = A, y = B)) + \n  geom_point(data = cls_test, aes(col = class), alpha = 1 / 2, cex = 3) +\n  geom_contour(aes(z = .pred_Class1), breaks = .5, col = \"black\", linewidth = 1) + \n  coord_fixed()\n```\n\n\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\n```\n  \n```{r}\n#| label: \"load\"\n#| include: false\nlibrary(tidymodels)\npkgs <- c(\"tidymodels\", \"brulee\", \"AppliedPredictiveModeling\")\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n\n## Introduction\n\n`r article_req_pkgs(pkgs)` You will also need the python torch library installed (see `?torch::install_torch()`).\n\nWe can create classification models with the tidymodels package [parsnip](https://parsnip.tidymodels.org/) to predict categorical quantities or class labels. Here, let's fit a single classification model using a neural network and evaluate using a validation set. While the [tune](https://tune.tidymodels.org/) package has functionality to also do this, the parsnip package is the center of attention in this article so that we can better understand its usage. \n\n## Fitting a neural network\n\n\nLet's fit a model to a small, two predictor classification data set. The data are in the modeldata package (part of tidymodels) and have been split into training, validation, and test data sets. In this analysis, the test set is left untouched; this article tries to emulate a good data usage methodology where the test set would only be evaluated once at the end after a variety of models have been considered. \n\n\n```{r}\n#| label: \"biv--split\"\nlibrary(AppliedPredictiveModeling)\n\nset.seed(321)\ncls_train <- quadBoundaryFunc(2000) %>% select(A = X1, B = X2, class)\ncls_val   <- quadBoundaryFunc( 500) %>% select(A = X1, B = X2, class)\ncls_test  <- quadBoundaryFunc( 500) %>% select(A = X1, B = X2, class)\n```\n\nA plot of the data shows two right-skewed predictors: \n\n```{r}\n#| label: \"biv-plot\"\n#| fig-width:  6\n#| fig-height:  6.1\nggplot(cls_train, aes(x = A, y = B, col = class)) + \n  geom_point(alpha = 1 / 4, cex = 3) + \n  coord_fixed()\n```\n\nLet's use a single hidden layer neural network to predict the outcome. To do this, we transform the predictor columns to be more symmetric (via the `step_BoxCox()` function) and on a common scale (using `step_normalize()`). We can use [recipes](https://recipes.tidymodels.org/) to do so:\n\n```{r}\n#| label: \"biv--proc\"\nbiv_rec <- \n  recipe(class ~ ., data = cls_train) %>%\n  step_normalize(all_predictors())\n```\n\nThis recipe is not directly executed; the steps will be estimated when the model is fit. \n\nWe can use the brulee package to fit a model with 5 hidden units and a 10% dropout rate, to regularize the model:\n\n```{r}\n#| label: \"biv-nnet\"\nnnet_spec <- \n  mlp(epochs = 1000, hidden_units = 10, penalty = 0.01, learn_rate = 0.1) %>% \n  set_engine(\"brulee\", validation = 0) %>% \n  set_mode(\"classification\")\n\nnnet_wflow <- \n  biv_rec %>% \n  workflow(nnet_spec)\n\nset.seed(987)\nnnet_fit <- fit(nnet_wflow, cls_train)\nnnet_fit %>% extract_fit_engine()\n```\n\n## Model performance\n\nIn parsnip, the `predict()` function can be used to characterize performance on the validation set. Since parsnip always produces tibble outputs, these can just be column bound to the original data: \n\n```{r}\n#| label: \"biv--perf\"\nval_results <- \n  cls_val %>%\n  bind_cols(\n    predict(nnet_fit, new_data = cls_val),\n    predict(nnet_fit, new_data = cls_val, type = \"prob\")\n  )\nval_results %>% slice(1:5)\n\nval_results %>% roc_auc(truth = class, .pred_Class1)\n\nval_results %>% accuracy(truth = class, .pred_class)\n\nval_results %>% conf_mat(truth = class, .pred_class)\n```\n\nLet's also create a grid to get a visual sense of the class boundary for the test set.\n\n```{r}\n#| label: \"biv-boundary\"\n#| fig-width:  6\n#| fig-height:  6.1\na_rng <- range(cls_train$A)\nb_rng <- range(cls_train$B)\nx_grid <-\n  expand.grid(A = seq(a_rng[1], a_rng[2], length.out = 100),\n              B = seq(b_rng[1], b_rng[2], length.out = 100))\n\n\n# Make predictions using the transformed predictors but \n# attach them to the predictors in the original units: \nx_grid <- \n  x_grid %>% \n  bind_cols(predict(nnet_fit, x_grid, type = \"prob\"))\n\nggplot(x_grid, aes(x = A, y = B)) + \n  geom_point(data = cls_test, aes(col = class), alpha = 1 / 2, cex = 3) +\n  geom_contour(aes(z = .pred_Class1), breaks = .5, col = \"black\", linewidth = 1) + \n  coord_fixed()\n```\n\n\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"include-after-body":["../../../resources.html"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","notebook-preview-download":"Download Notebook","notebook-preview-back":"Back to Article"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.92","theme":["cosmo","../../../styles.scss","../../../styles-frontpage.scss"],"quarto-required":">= 1.3.353","linestretch":1.6,"grid":{"body-width":"840px"},"title":"Classification models using a neural network","categories":["model fitting","torch","neural networks"],"type":"learn-subsection","weight":2,"description":"Train a classification model and evaluate its performance.\n"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}