{"title":"Build a model","markdown":{"yaml":{"title":"Build a model","weight":1,"categories":["model fitting","parsnip","broom"],"description":"Get started by learning how to specify and train a model using tidymodels.\n","toc-location":"body","toc-depth":2,"toc-title":"","css":"../styles.css","include-after-body":"../repo-actions-delete.html"},"headingText":"Introduction","headingAttr":{"id":"intro","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\n```\n\n```{r}\n#| label: \"load\"\n#| include: false\n#| message: false\n#| warning: false\nlibrary(readr)\nlibrary(rstanarm)\nlibrary(tidymodels)\nlibrary(broom.mixed)\nlibrary(dotwhisker)\n\npkgs <- c(\"tidymodels\", \"readr\", \"rstanarm\", \"broom.mixed\", \"dotwhisker\")\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n\n\n\nHow do you create a statistical model using tidymodels? In this article, we will walk you through the steps. We start with data for modeling, learn how to specify and train models with different engines using the [parsnip package](https://parsnip.tidymodels.org/), and understand why these functions are designed this way.\n\n`r article_req_pkgs(pkgs)`\n\n```{r}\n#| eval: false\nlibrary(tidymodels)  # for the parsnip package, along with the rest of tidymodels\n\n# Helper packages\nlibrary(readr)       # for importing data\nlibrary(broom.mixed) # for converting bayesian models to tidy tibbles\nlibrary(dotwhisker)  # for visualizing regression results\n```\n\n\n{{< test-drive url=\"https://rstudio.cloud/project/2674862\" >}}\n\n\n## The Sea Urchins Data {#data}\n\nLet's use the data from [Constable (1993)](https://link.springer.com/article/10.1007/BF00349318) to explore how three different feeding regimes affect the size of sea urchins over time. The initial size of the sea urchins at the beginning of the experiment probably affects how big they grow as they are fed. \n\nTo start, let's read our urchins data into R, which we'll do by providing [`readr::read_csv()`](https://readr.tidyverse.org/reference/read_delim.html) with a url where our CSV data is located (\"<https://tidymodels.org/start/models/urchins.csv>\"):\n\n```{r}\n#| label: \"data\"\nurchins <-\n  # Data were assembled for a tutorial \n  # at https://www.flutterbys.com.au/stats/tut/tut7.5a.html\n  read_csv(\"https://tidymodels.org/start/models/urchins.csv\") %>% \n  # Change the names to be a little more verbose\n  setNames(c(\"food_regime\", \"initial_volume\", \"width\")) %>% \n  # Factors are very helpful for modeling, so we convert one column\n  mutate(food_regime = factor(food_regime, levels = c(\"Initial\", \"Low\", \"High\")))\n```\n\nLet's take a quick look at the data:\n\n```{r}\nurchins\n```\n\nThe urchins data is a [tibble](https://tibble.tidyverse.org/index.html). If you are new to tibbles, the best place to start is the [tibbles chapter](https://r4ds.had.co.nz/tibbles.html) in *R for Data Science*. For each of the `r nrow(urchins)` urchins, we know their:\n\n+ experimental feeding regime group (`food_regime`: either `Initial`, `Low`, or `High`),\n+ size in milliliters at the start of the experiment (`initial_volume`), and\n+ suture width at the end of the experiment (`width`).\n\nAs a first step in modeling, it's always a good idea to plot the data: \n\n```{r}\n#| label: \"urchin-plot\"\nggplot(urchins,\n       aes(x = initial_volume, \n           y = width, \n           group = food_regime, \n           col = food_regime)) + \n  geom_point() + \n  geom_smooth(method = lm, se = FALSE) +\n  scale_color_viridis_d(option = \"plasma\", end = .7)\n```\n\nWe can see that urchins that were larger in volume at the start of the experiment tended to have wider sutures at the end, but the slopes of the lines look different so this effect may depend on the feeding regime condition.\n\n## Build and fit a model {#build-model}\n\nA standard two-way analysis of variance ([ANOVA](https://www.itl.nist.gov/div898/handbook/prc/section4/prc43.htm)) model makes sense for this dataset because we have both a continuous predictor and a categorical predictor. Since the slopes appear to be different for at least two of the feeding regimes, let's build a model that allows for two-way interactions. Specifying an R formula with our variables in this way: \n\n```{r}\n#| label: \"two-way-int\"\n#| eval: false\nwidth ~ initial_volume * food_regime\n```\n\nallows our regression model depending on initial volume to have separate slopes and intercepts for each food regime. \n\nFor this kind of model, ordinary least squares is a good initial approach. With tidymodels, we start by specifying the _functional form_ of the model that we want using the [parsnip package](https://parsnip.tidymodels.org/). Since there is a numeric outcome and the model should be linear with slopes and intercepts, the model type is [\"linear regression\"](https://parsnip.tidymodels.org/reference/linear_reg.html). We can declare this with: \n\n\n```{r}\n#| label: \"lm-tm\"\nlinear_reg()\n```\n\nThat is pretty underwhelming since, on its own, it doesn't really do much. However, now that the type of model has been specified, we can think about a method for _fitting_ or training the model, the model **engine**. The engine value is often a mash-up of the software that can be used to fit or train the model as well as the estimation method. The default for `linear_reg()` is `\"lm\"` for ordinary least squares, as you can see above. We could set a non-default option instead:\n\n```{r}\n#| label: \"lm-spec\"\nlinear_reg() %>% \n  set_engine(\"keras\")\n```\n\nThe [documentation page for `linear_reg()`](https://parsnip.tidymodels.org/reference/linear_reg.html) lists all the possible engines. We'll save our model object using the default engine as `lm_mod`.\n\n```{r}\nlm_mod <- linear_reg()\n```\n\nFrom here, the model can be estimated or trained using the [`fit()`](https://parsnip.tidymodels.org/reference/fit.html) function:\n\n```{r}\n#| label: \"lm-fit\"\nlm_fit <- \n  lm_mod %>% \n  fit(width ~ initial_volume * food_regime, data = urchins)\nlm_fit\n```\n\nPerhaps our analysis requires a description of the model parameter estimates and their statistical properties. Although the `summary()` function for `lm` objects can provide that, it gives the results back in an unwieldy format. Many models have a `tidy()` method that provides the summary results in a more predictable and useful format (e.g. a data frame with standard column names): \n\n```{r}\n#| label: \"lm-table\"\ntidy(lm_fit)\n```\n\nThis kind of output can be used to generate a dot-and-whisker plot of our regression results using the dotwhisker package:\n\n```{r}\n#| label: \"dwplot\"\ntidy(lm_fit) %>% \n  dwplot(dot_args = list(size = 2, color = \"black\"),\n         whisker_args = list(color = \"black\"),\n         vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n```\n\n\n## Use a model to predict {#predict-model}\n\nThis fitted object `lm_fit` has the `lm` model output built-in, which you can access with `lm_fit$fit`, but there are some benefits to using the fitted parsnip model object when it comes to predicting.\n\nSuppose that, for a publication, it would be particularly interesting to make a plot of the mean body size for urchins that started the experiment with an initial volume of 20ml. To create such a graph, we start with some new example data that we will make predictions for, to show in our graph:\n\n```{r}\n#| label: \"new-points\"\nnew_points <- expand.grid(initial_volume = 20, \n                          food_regime = c(\"Initial\", \"Low\", \"High\"))\nnew_points\n```\n\nTo get our predicted results, we can use the `predict()` function to find the mean values at 20ml. \n\nIt is also important to communicate the variability, so we also need to find the predicted confidence intervals. If we had used `lm()` to fit the model directly, a few minutes of reading the [documentation page](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.lm.html) for `predict.lm()` would explain how to do this. However, if we decide to use a different model to estimate urchin size (_spoiler:_ we will!), it is likely that a completely different syntax would be required. \n\nInstead, with tidymodels, the types of predicted values are standardized so that we can use the same syntax to get these values. \n\nFirst, let's generate the mean body width values: \n\n```{r}\n#| label: \"lm-pred-mean\"\nmean_pred <- predict(lm_fit, new_data = new_points)\nmean_pred\n```\n\nWhen making predictions, the tidymodels convention is to always produce a tibble of results with standardized column names. This makes it easy to combine the original data and the predictions in a usable format: \n\n```{r}\n#| label: \"lm-all-pred\"\nconf_int_pred <- predict(lm_fit, \n                         new_data = new_points, \n                         type = \"conf_int\")\nconf_int_pred\n\n# Now combine: \nplot_data <- \n  new_points %>% \n  bind_cols(mean_pred) %>% \n  bind_cols(conf_int_pred)\n\n# and plot:\nggplot(plot_data, aes(x = food_regime)) + \n  geom_point(aes(y = .pred)) + \n  geom_errorbar(aes(ymin = .pred_lower, \n                    ymax = .pred_upper),\n                width = .2) + \n  labs(y = \"urchin size\")\n```\n\n## Model with a different engine {#new-engine}\n\nEvery one on your team is happy with that plot _except_ that one person who just read their first book on [Bayesian analysis](https://bayesian.org/what-is-bayesian-analysis/). They are interested in knowing if the results would be different if the model were estimated using a Bayesian approach. In such an analysis, a [_prior distribution_](https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7) needs to be declared for each model parameter that represents the possible values of the parameters (before being exposed to the observed data). After some discussion, the group agrees that the priors should be bell-shaped but, since no one has any idea what the range of values should be, to take a conservative approach and make the priors _wide_ using a Cauchy distribution (which is the same as a t-distribution with a single degree of freedom).\n\nThe [documentation](https://mc-stan.org/rstanarm/articles/priors.html) on the rstanarm package shows us that the `stan_glm()` function can be used to estimate this model, and that the function arguments that need to be specified are called `prior` and `prior_intercept`. It turns out that `linear_reg()` has a [`stan` engine](https://parsnip.tidymodels.org/reference/linear_reg.html#details). Since these prior distribution arguments are specific to the Stan software, they are passed as arguments to [`parsnip::set_engine()`](https://parsnip.tidymodels.org/reference/set_engine.html). After that, the same exact `fit()` call is used:\n\n```{r}\n#| label: \"go-stan\"\n#| message: false\n# set the prior distribution\nprior_dist <- rstanarm::student_t(df = 1)\n\nset.seed(123)\n\n# make the parsnip model\nbayes_mod <-   \n  linear_reg() %>% \n  set_engine(\"stan\", \n             prior_intercept = prior_dist, \n             prior = prior_dist) \n\n# train the model\nbayes_fit <- \n  bayes_mod %>% \n  fit(width ~ initial_volume * food_regime, data = urchins)\n\nprint(bayes_fit, digits = 5)\n```\n\nThis kind of Bayesian analysis (like many models) involves randomly generated numbers in its fitting procedure. We can use `set.seed()` to ensure that the same (pseudo-)random numbers are generated each time we run this code. The number `123` isn't special or related to our data; it is just a \"seed\" used to choose random numbers.\n\nTo update the parameter table, the `tidy()` method is once again used: \n\n```{r}\n#| label: \"tidy-stan\"\ntidy(bayes_fit, conf.int = TRUE)\n```\n\nA goal of the tidymodels packages is that the **interfaces to common tasks are standardized** (as seen in the `tidy()` results above). The same is true for getting predictions; we can use the same code even though the underlying packages use very different syntax:\n\n```{r}\n#| label: \"stan-pred\"\nbayes_plot_data <- \n  new_points %>% \n  bind_cols(predict(bayes_fit, new_data = new_points)) %>% \n  bind_cols(predict(bayes_fit, new_data = new_points, type = \"conf_int\"))\n\nggplot(bayes_plot_data, aes(x = food_regime)) + \n  geom_point(aes(y = .pred)) + \n  geom_errorbar(aes(ymin = .pred_lower, ymax = .pred_upper), width = .2) + \n  labs(y = \"urchin size\") + \n  ggtitle(\"Bayesian model with t(1) prior distribution\")\n```\n\nThis isn't very different from the non-Bayesian results (except in interpretation). \n\n::: {.callout-note}\nThe [parsnip](https://parsnip.tidymodels.org/) package can work with many model types, engines, and arguments. Check out [tidymodels.org/find/parsnip](/find/parsnip/) to see what is available. \n:::\n\n## Why does it work that way? {#why}\n\nThe extra step of defining the model using a function like `linear_reg()` might seem superfluous since a call to `lm()` is much more succinct. However, the problem with standard modeling functions is that they don't separate what you want to do from the execution. For example, the process of executing a formula has to happen repeatedly across model calls even when the formula does not change; we can't recycle those computations. \n\nAlso, using the tidymodels framework, we can do some interesting things by incrementally creating a model (instead of using single function call). [Model tuning](/start/tuning/) with tidymodels uses the specification of the model to declare what parts of the model should be tuned. That would be very difficult to do if `linear_reg()` immediately fit the model. \n\nIf you are familiar with the tidyverse, you may have noticed that our modeling code uses the magrittr pipe (`%>%`). With dplyr and other tidyverse packages, the pipe works well because all of the functions take the _data_ as the first argument. For example: \n\n```{r}\n#| label: \"tidy-data\"\nurchins %>% \n  group_by(food_regime) %>% \n  summarize(med_vol = median(initial_volume))\n```\n\nwhereas the modeling code uses the pipe to pass around the _model object_:\n\n```{r}\n#| label: \"tidy-model\"\n#| eval: false\nbayes_mod %>% \n  fit(width ~ initial_volume * food_regime, data = urchins)\n```\n\nThis may seem jarring if you have used dplyr a lot, but it is extremely similar to how ggplot2 operates:\n\n```{r}\n#| eval: false\nggplot(urchins,\n       aes(initial_volume, width)) +      # returns a ggplot object \n  geom_jitter() +                         # same\n  geom_smooth(method = lm, se = FALSE) +  # same                    \n  labs(x = \"Volume\", y = \"Width\")         # etc\n```\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\n```\n\n```{r}\n#| label: \"load\"\n#| include: false\n#| message: false\n#| warning: false\nlibrary(readr)\nlibrary(rstanarm)\nlibrary(tidymodels)\nlibrary(broom.mixed)\nlibrary(dotwhisker)\n\npkgs <- c(\"tidymodels\", \"readr\", \"rstanarm\", \"broom.mixed\", \"dotwhisker\")\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n\n\n## Introduction {#intro}\n\nHow do you create a statistical model using tidymodels? In this article, we will walk you through the steps. We start with data for modeling, learn how to specify and train models with different engines using the [parsnip package](https://parsnip.tidymodels.org/), and understand why these functions are designed this way.\n\n`r article_req_pkgs(pkgs)`\n\n```{r}\n#| eval: false\nlibrary(tidymodels)  # for the parsnip package, along with the rest of tidymodels\n\n# Helper packages\nlibrary(readr)       # for importing data\nlibrary(broom.mixed) # for converting bayesian models to tidy tibbles\nlibrary(dotwhisker)  # for visualizing regression results\n```\n\n\n{{< test-drive url=\"https://rstudio.cloud/project/2674862\" >}}\n\n\n## The Sea Urchins Data {#data}\n\nLet's use the data from [Constable (1993)](https://link.springer.com/article/10.1007/BF00349318) to explore how three different feeding regimes affect the size of sea urchins over time. The initial size of the sea urchins at the beginning of the experiment probably affects how big they grow as they are fed. \n\nTo start, let's read our urchins data into R, which we'll do by providing [`readr::read_csv()`](https://readr.tidyverse.org/reference/read_delim.html) with a url where our CSV data is located (\"<https://tidymodels.org/start/models/urchins.csv>\"):\n\n```{r}\n#| label: \"data\"\nurchins <-\n  # Data were assembled for a tutorial \n  # at https://www.flutterbys.com.au/stats/tut/tut7.5a.html\n  read_csv(\"https://tidymodels.org/start/models/urchins.csv\") %>% \n  # Change the names to be a little more verbose\n  setNames(c(\"food_regime\", \"initial_volume\", \"width\")) %>% \n  # Factors are very helpful for modeling, so we convert one column\n  mutate(food_regime = factor(food_regime, levels = c(\"Initial\", \"Low\", \"High\")))\n```\n\nLet's take a quick look at the data:\n\n```{r}\nurchins\n```\n\nThe urchins data is a [tibble](https://tibble.tidyverse.org/index.html). If you are new to tibbles, the best place to start is the [tibbles chapter](https://r4ds.had.co.nz/tibbles.html) in *R for Data Science*. For each of the `r nrow(urchins)` urchins, we know their:\n\n+ experimental feeding regime group (`food_regime`: either `Initial`, `Low`, or `High`),\n+ size in milliliters at the start of the experiment (`initial_volume`), and\n+ suture width at the end of the experiment (`width`).\n\nAs a first step in modeling, it's always a good idea to plot the data: \n\n```{r}\n#| label: \"urchin-plot\"\nggplot(urchins,\n       aes(x = initial_volume, \n           y = width, \n           group = food_regime, \n           col = food_regime)) + \n  geom_point() + \n  geom_smooth(method = lm, se = FALSE) +\n  scale_color_viridis_d(option = \"plasma\", end = .7)\n```\n\nWe can see that urchins that were larger in volume at the start of the experiment tended to have wider sutures at the end, but the slopes of the lines look different so this effect may depend on the feeding regime condition.\n\n## Build and fit a model {#build-model}\n\nA standard two-way analysis of variance ([ANOVA](https://www.itl.nist.gov/div898/handbook/prc/section4/prc43.htm)) model makes sense for this dataset because we have both a continuous predictor and a categorical predictor. Since the slopes appear to be different for at least two of the feeding regimes, let's build a model that allows for two-way interactions. Specifying an R formula with our variables in this way: \n\n```{r}\n#| label: \"two-way-int\"\n#| eval: false\nwidth ~ initial_volume * food_regime\n```\n\nallows our regression model depending on initial volume to have separate slopes and intercepts for each food regime. \n\nFor this kind of model, ordinary least squares is a good initial approach. With tidymodels, we start by specifying the _functional form_ of the model that we want using the [parsnip package](https://parsnip.tidymodels.org/). Since there is a numeric outcome and the model should be linear with slopes and intercepts, the model type is [\"linear regression\"](https://parsnip.tidymodels.org/reference/linear_reg.html). We can declare this with: \n\n\n```{r}\n#| label: \"lm-tm\"\nlinear_reg()\n```\n\nThat is pretty underwhelming since, on its own, it doesn't really do much. However, now that the type of model has been specified, we can think about a method for _fitting_ or training the model, the model **engine**. The engine value is often a mash-up of the software that can be used to fit or train the model as well as the estimation method. The default for `linear_reg()` is `\"lm\"` for ordinary least squares, as you can see above. We could set a non-default option instead:\n\n```{r}\n#| label: \"lm-spec\"\nlinear_reg() %>% \n  set_engine(\"keras\")\n```\n\nThe [documentation page for `linear_reg()`](https://parsnip.tidymodels.org/reference/linear_reg.html) lists all the possible engines. We'll save our model object using the default engine as `lm_mod`.\n\n```{r}\nlm_mod <- linear_reg()\n```\n\nFrom here, the model can be estimated or trained using the [`fit()`](https://parsnip.tidymodels.org/reference/fit.html) function:\n\n```{r}\n#| label: \"lm-fit\"\nlm_fit <- \n  lm_mod %>% \n  fit(width ~ initial_volume * food_regime, data = urchins)\nlm_fit\n```\n\nPerhaps our analysis requires a description of the model parameter estimates and their statistical properties. Although the `summary()` function for `lm` objects can provide that, it gives the results back in an unwieldy format. Many models have a `tidy()` method that provides the summary results in a more predictable and useful format (e.g. a data frame with standard column names): \n\n```{r}\n#| label: \"lm-table\"\ntidy(lm_fit)\n```\n\nThis kind of output can be used to generate a dot-and-whisker plot of our regression results using the dotwhisker package:\n\n```{r}\n#| label: \"dwplot\"\ntidy(lm_fit) %>% \n  dwplot(dot_args = list(size = 2, color = \"black\"),\n         whisker_args = list(color = \"black\"),\n         vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n```\n\n\n## Use a model to predict {#predict-model}\n\nThis fitted object `lm_fit` has the `lm` model output built-in, which you can access with `lm_fit$fit`, but there are some benefits to using the fitted parsnip model object when it comes to predicting.\n\nSuppose that, for a publication, it would be particularly interesting to make a plot of the mean body size for urchins that started the experiment with an initial volume of 20ml. To create such a graph, we start with some new example data that we will make predictions for, to show in our graph:\n\n```{r}\n#| label: \"new-points\"\nnew_points <- expand.grid(initial_volume = 20, \n                          food_regime = c(\"Initial\", \"Low\", \"High\"))\nnew_points\n```\n\nTo get our predicted results, we can use the `predict()` function to find the mean values at 20ml. \n\nIt is also important to communicate the variability, so we also need to find the predicted confidence intervals. If we had used `lm()` to fit the model directly, a few minutes of reading the [documentation page](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.lm.html) for `predict.lm()` would explain how to do this. However, if we decide to use a different model to estimate urchin size (_spoiler:_ we will!), it is likely that a completely different syntax would be required. \n\nInstead, with tidymodels, the types of predicted values are standardized so that we can use the same syntax to get these values. \n\nFirst, let's generate the mean body width values: \n\n```{r}\n#| label: \"lm-pred-mean\"\nmean_pred <- predict(lm_fit, new_data = new_points)\nmean_pred\n```\n\nWhen making predictions, the tidymodels convention is to always produce a tibble of results with standardized column names. This makes it easy to combine the original data and the predictions in a usable format: \n\n```{r}\n#| label: \"lm-all-pred\"\nconf_int_pred <- predict(lm_fit, \n                         new_data = new_points, \n                         type = \"conf_int\")\nconf_int_pred\n\n# Now combine: \nplot_data <- \n  new_points %>% \n  bind_cols(mean_pred) %>% \n  bind_cols(conf_int_pred)\n\n# and plot:\nggplot(plot_data, aes(x = food_regime)) + \n  geom_point(aes(y = .pred)) + \n  geom_errorbar(aes(ymin = .pred_lower, \n                    ymax = .pred_upper),\n                width = .2) + \n  labs(y = \"urchin size\")\n```\n\n## Model with a different engine {#new-engine}\n\nEvery one on your team is happy with that plot _except_ that one person who just read their first book on [Bayesian analysis](https://bayesian.org/what-is-bayesian-analysis/). They are interested in knowing if the results would be different if the model were estimated using a Bayesian approach. In such an analysis, a [_prior distribution_](https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7) needs to be declared for each model parameter that represents the possible values of the parameters (before being exposed to the observed data). After some discussion, the group agrees that the priors should be bell-shaped but, since no one has any idea what the range of values should be, to take a conservative approach and make the priors _wide_ using a Cauchy distribution (which is the same as a t-distribution with a single degree of freedom).\n\nThe [documentation](https://mc-stan.org/rstanarm/articles/priors.html) on the rstanarm package shows us that the `stan_glm()` function can be used to estimate this model, and that the function arguments that need to be specified are called `prior` and `prior_intercept`. It turns out that `linear_reg()` has a [`stan` engine](https://parsnip.tidymodels.org/reference/linear_reg.html#details). Since these prior distribution arguments are specific to the Stan software, they are passed as arguments to [`parsnip::set_engine()`](https://parsnip.tidymodels.org/reference/set_engine.html). After that, the same exact `fit()` call is used:\n\n```{r}\n#| label: \"go-stan\"\n#| message: false\n# set the prior distribution\nprior_dist <- rstanarm::student_t(df = 1)\n\nset.seed(123)\n\n# make the parsnip model\nbayes_mod <-   \n  linear_reg() %>% \n  set_engine(\"stan\", \n             prior_intercept = prior_dist, \n             prior = prior_dist) \n\n# train the model\nbayes_fit <- \n  bayes_mod %>% \n  fit(width ~ initial_volume * food_regime, data = urchins)\n\nprint(bayes_fit, digits = 5)\n```\n\nThis kind of Bayesian analysis (like many models) involves randomly generated numbers in its fitting procedure. We can use `set.seed()` to ensure that the same (pseudo-)random numbers are generated each time we run this code. The number `123` isn't special or related to our data; it is just a \"seed\" used to choose random numbers.\n\nTo update the parameter table, the `tidy()` method is once again used: \n\n```{r}\n#| label: \"tidy-stan\"\ntidy(bayes_fit, conf.int = TRUE)\n```\n\nA goal of the tidymodels packages is that the **interfaces to common tasks are standardized** (as seen in the `tidy()` results above). The same is true for getting predictions; we can use the same code even though the underlying packages use very different syntax:\n\n```{r}\n#| label: \"stan-pred\"\nbayes_plot_data <- \n  new_points %>% \n  bind_cols(predict(bayes_fit, new_data = new_points)) %>% \n  bind_cols(predict(bayes_fit, new_data = new_points, type = \"conf_int\"))\n\nggplot(bayes_plot_data, aes(x = food_regime)) + \n  geom_point(aes(y = .pred)) + \n  geom_errorbar(aes(ymin = .pred_lower, ymax = .pred_upper), width = .2) + \n  labs(y = \"urchin size\") + \n  ggtitle(\"Bayesian model with t(1) prior distribution\")\n```\n\nThis isn't very different from the non-Bayesian results (except in interpretation). \n\n::: {.callout-note}\nThe [parsnip](https://parsnip.tidymodels.org/) package can work with many model types, engines, and arguments. Check out [tidymodels.org/find/parsnip](/find/parsnip/) to see what is available. \n:::\n\n## Why does it work that way? {#why}\n\nThe extra step of defining the model using a function like `linear_reg()` might seem superfluous since a call to `lm()` is much more succinct. However, the problem with standard modeling functions is that they don't separate what you want to do from the execution. For example, the process of executing a formula has to happen repeatedly across model calls even when the formula does not change; we can't recycle those computations. \n\nAlso, using the tidymodels framework, we can do some interesting things by incrementally creating a model (instead of using single function call). [Model tuning](/start/tuning/) with tidymodels uses the specification of the model to declare what parts of the model should be tuned. That would be very difficult to do if `linear_reg()` immediately fit the model. \n\nIf you are familiar with the tidyverse, you may have noticed that our modeling code uses the magrittr pipe (`%>%`). With dplyr and other tidyverse packages, the pipe works well because all of the functions take the _data_ as the first argument. For example: \n\n```{r}\n#| label: \"tidy-data\"\nurchins %>% \n  group_by(food_regime) %>% \n  summarize(med_vol = median(initial_volume))\n```\n\nwhereas the modeling code uses the pipe to pass around the _model object_:\n\n```{r}\n#| label: \"tidy-model\"\n#| eval: false\nbayes_mod %>% \n  fit(width ~ initial_volume * food_regime, data = urchins)\n```\n\nThis may seem jarring if you have used dplyr a lot, but it is extremely similar to how ggplot2 operates:\n\n```{r}\n#| eval: false\nggplot(urchins,\n       aes(initial_volume, width)) +      # returns a ggplot object \n  geom_jitter() +                         # same\n  geom_smooth(method = lm, se = FALSE) +  # same                    \n  labs(x = \"Volume\", y = \"Width\")         # etc\n```\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"css":["../styles.css"],"include-after-body":["../repo-actions-delete.html"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","notebook-preview-download":"Download Notebook","notebook-preview-back":"Back to Article"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.92","theme":["cosmo","../../styles.scss","../../styles-frontpage.scss"],"quarto-required":">= 1.3.353","linestretch":1.6,"grid":{"body-width":"840px"},"title":"Build a model","weight":1,"categories":["model fitting","parsnip","broom"],"description":"Get started by learning how to specify and train a model using tidymodels.\n","toc-location":"body","toc-title":""},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}