{"title":"Preprocess your data with recipes","markdown":{"yaml":{"title":"Preprocess your data with recipes","weight":2,"categories":["pre-processing","recipes","parsnip","workflows","yardstick","broom"],"description":"Prepare data for modeling with modular preprocessing steps.\n","toc-location":"body","toc-depth":2,"toc-title":"","css":"../styles.css","include-after-body":"../repo-actions-delete.html"},"headingText":"Introduction","headingAttr":{"id":"intro","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\n```\n\n```{r}\n#| label: \"load\"\n#| include: false\n#| message: false\n#| warning: false\nlibrary(tidymodels)\nlibrary(nycflights13)\nlibrary(kableExtra)\nlibrary(skimr)\npkgs <- c(\"tidymodels\", \"nycflights13\", \"skimr\")\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n\nIn our [*Build a Model*](/start/models/) article, we learned how to specify and train models with different engines using the [parsnip package](https://parsnip.tidymodels.org/). In this article, we'll explore another tidymodels package, [recipes](https://recipes.tidymodels.org/), which is designed to help you preprocess your data *before* training your model. Recipes are built as a series of preprocessing steps, such as:\n\n-   converting qualitative predictors to indicator variables (also known as dummy variables),\n\n-   transforming data to be on a different scale (e.g., taking the logarithm of a variable),\n\n-   transforming whole groups of predictors together,\n\n-   extracting key features from raw variables (e.g., getting the day of the week out of a date variable),\n\nand so on. If you are familiar with R's formula interface, a lot of this might sound familiar and like what a formula already does. Recipes can be used to do many of the same things, but they have a much wider range of possibilities. This article shows how to use recipes for modeling.\n\n`r article_req_pkgs(pkgs)`\n\n```{r}\n#| eval: false\nlibrary(tidymodels)      # for the recipes package, along with the rest of tidymodels\n\n# Helper packages\nlibrary(nycflights13)    # for flight data\nlibrary(skimr)           # for variable summaries\n```\n\n{{< test-drive url=\"https://rstudio.cloud/project/2674862\" >}}\n\n## The New York City flight data {#data}\n\n```{r}\n#| label: \"flight-start\"\n#| echo: false\nset.seed(123)\n\nflight_data <- \n  flights %>% \n  mutate(\n    # Convert the arrival delay to a factor\n    arr_delay = ifelse(arr_delay >= 30, \"late\", \"on_time\"),\n    arr_delay = factor(arr_delay),\n    # We will use the date (not date-time) in the recipe below\n    date = lubridate::as_date(time_hour)\n  ) %>% \n  # Include the weather data\n  inner_join(weather, by = c(\"origin\", \"time_hour\")) %>% \n  # Only retain the specific columns we will use\n  select(dep_time, flight, origin, dest, air_time, distance, \n         carrier, date, arr_delay, time_hour) %>% \n  # Exclude missing data\n  na.omit() %>% \n  # For creating models, it is better to have qualitative columns\n  # encoded as factors (instead of character strings)\n  mutate_if(is.character, as.factor)\n```\n\nLet's use the [nycflights13 data](https://github.com/hadley/nycflights13) to predict whether a plane arrives more than 30 minutes late. This data set contains information on `r scales::comma(nrow(flight_data))` flights departing near New York City in 2013. Let's start by loading the data and making a few changes to the variables:\n\n```{r}\n#| ref.label: \"flight-start\"\n\n```\n\nWe can see that about `r percent(mean(flight_data$arr_delay == \"late\"))` of the flights in this data set arrived more than 30 minutes late.\n\n```{r}\n#| label: \"count-delays\"\nflight_data %>% \n  count(arr_delay) %>% \n  mutate(prop = n/sum(n))\n```\n\nBefore we start building up our recipe, let's take a quick look at a few specific variables that will be important for both preprocessing and modeling.\n\nFirst, notice that the variable we created called `arr_delay` is a factor variable; it is important that our outcome variable for training a logistic regression model is a factor.\n\n```{r}\n#| label: \"glimpse-flights\"\nglimpse(flight_data)\n```\n\nSecond, there are two variables that we don't want to use as predictors in our model, but that we would like to retain as identification variables that can be used to troubleshoot poorly predicted data points. These are `flight`, a numeric value, and `time_hour`, a date-time value.\n\nThird, there are `r length(levels(flight_data$dest))` flight destinations contained in `dest` and `r length(levels(flight_data$carrier))` distinct `carrier`s.\n\n```{r}\n#| label: \"skim-flights\"\nflight_data %>% \n  skimr::skim(dest, carrier) \n```\n\nBecause we'll be using a simple logistic regression model, the variables `dest` and `carrier` will be converted to [dummy variables](https://bookdown.org/max/FES/creating-dummy-variables-for-unordered-categories.html). However, some of these values do not occur very frequently and this could complicate our analysis. We'll discuss specific steps later in this article that we can add to our recipe to address this issue before modeling.\n\n## Data splitting {#data-split}\n\nTo get started, let's split this single dataset into two: a *training* set and a *testing* set. We'll keep most of the rows in the original dataset (subset chosen randomly) in the *training* set. The training data will be used to *fit* the model, and the *testing* set will be used to measure model performance.\n\nTo do this, we can use the [rsample](https://rsample.tidymodels.org/) package to create an object that contains the information on *how* to split the data, and then two more rsample functions to create data frames for the training and testing sets:\n\n```{r}\n#| label: \"split\"\n# Fix the random numbers by setting the seed \n# This enables the analysis to be reproducible when random numbers are used \nset.seed(222)\n# Put 3/4 of the data into the training set \ndata_split <- initial_split(flight_data, prop = 3/4)\n\n# Create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n```\n\n## Create recipe and roles {#recipe}\n\nTo get started, let's create a recipe for a simple logistic regression model. Before training the model, we can use a recipe to create a few new predictors and conduct some preprocessing required by the model.\n\nLet's initiate a new recipe:\n\n```{r}\n#| label: \"initial-recipe\"\nflights_rec <- \n  recipe(arr_delay ~ ., data = train_data) \n```\n\nThe [`recipe()` function](https://recipes.tidymodels.org/reference/recipe.html) as we used it here has two arguments:\n\n-   A **formula**. Any variable on the left-hand side of the tilde (`~`) is considered the model outcome (here, `arr_delay`). On the right-hand side of the tilde are the predictors. Variables may be listed by name, or you can use the dot (`.`) to indicate all other variables as predictors.\n\n-   The **data**. A recipe is associated with the data set used to create the model. This will typically be the *training* set, so `data = train_data` here. Naming a data set doesn't actually change the data itself; it is only used to catalog the names of the variables and their types, like factors, integers, dates, etc.\n\nNow we can add [roles](https://recipes.tidymodels.org/reference/roles.html) to this recipe. We can use the [`update_role()` function](https://recipes.tidymodels.org/reference/roles.html) to let recipes know that `flight` and `time_hour` are variables with a custom role that we called `\"ID\"` (a role can have any character value). Whereas our formula included all variables in the training set other than `arr_delay` as predictors, this tells the recipe to keep these two variables but not use them as either outcomes or predictors.\n\n```{r}\n#| label: \"recipe-roles\"\nflights_rec <- \n  recipe(arr_delay ~ ., data = train_data) %>% \n  update_role(flight, time_hour, new_role = \"ID\") \n```\n\nThis step of adding roles to a recipe is optional; the purpose of using it here is that those two variables can be retained in the data but not included in the model. This can be convenient when, after the model is fit, we want to investigate some poorly predicted value. These ID columns will be available and can be used to try to understand what went wrong.\n\nTo get the current set of variables and roles, use the `summary()` function:\n\n```{r}\n#| label: \"summary\"\nsummary(flights_rec)\n```\n\n## Create features {#features}\n\nNow we can start adding steps onto our recipe using the pipe operator. Perhaps it is reasonable for the date of the flight to have an effect on the likelihood of a late arrival. A little bit of **feature engineering** might go a long way to improving our model. How should the date be encoded into the model? The `date` column has an R `date` object so including that column \"as is\" will mean that the model will convert it to a numeric format equal to the number of days after a reference date:\n\n```{r}\n#| label: \"dates\"\nflight_data %>% \n  distinct(date) %>% \n  mutate(numeric_date = as.numeric(date)) \n```\n\nIt's possible that the numeric date variable is a good option for modeling; perhaps the model would benefit from a linear trend between the log-odds of a late arrival and the numeric date variable. However, it might be better to add model terms *derived* from the date that have a better potential to be important to the model. For example, we could derive the following meaningful features from the single `date` variable:\n\n-   the day of the week,\n\n-   the month, and\n\n-   whether or not the date corresponds to a holiday.\n\nLet's do all three of these by adding steps to our recipe:\n\n```{r}\n#| label: \"date-recipe\"\nflights_rec <- \n  recipe(arr_delay ~ ., data = train_data) %>% \n  update_role(flight, time_hour, new_role = \"ID\") %>% \n  step_date(date, features = c(\"dow\", \"month\")) %>%               \n  step_holiday(date, \n               holidays = timeDate::listHolidays(\"US\"), \n               keep_original_cols = FALSE)\n```\n\nWhat do each of these steps do?\n\n-   With [`step_date()`](https://recipes.tidymodels.org/reference/step_date.html), we created two new factor columns with the appropriate day of the week and the month.\n\n-   With [`step_holiday()`](https://recipes.tidymodels.org/reference/step_holiday.html), we created a binary variable indicating whether the current date is a holiday or not. The argument value of `timeDate::listHolidays(\"US\")` uses the [timeDate package](https://cran.r-project.org/web/packages/timeDate/index.html) to list the `r length(timeDate::listHolidays(\"US\"))` standard US holidays.\n\n-   With `keep_original_cols = FALSE`, we remove the original `date` variable since we no longer want it in the model. Many recipe steps that create new variables have this argument.\n\nNext, we'll turn our attention to the variable types of our predictors. Because we plan to train a logistic regression model, we know that predictors will ultimately need to be numeric, as opposed to nominal data like strings and factor variables. In other words, there may be a difference in how we store our data (in factors inside a data frame), and how the underlying equations require them (a purely numeric matrix).\n\nFor factors like `dest` and `origin`, [standard practice](https://bookdown.org/max/FES/creating-dummy-variables-for-unordered-categories.html) is to convert them into *dummy* or *indicator* variables to make them numeric. These are binary values for each level of the factor. For example, our `origin` variable has values of `\"EWR\"`, `\"JFK\"`, and `\"LGA\"`. The standard dummy variable encoding, shown below, will create *two* numeric columns of the data that are 1 when the originating airport is `\"JFK\"` or `\"LGA\"` and zero otherwise, respectively.\n\n```{r}\n#| label: \"calc-dummy\"\n#| include: false\nfour_origins <- \n  train_data %>% \n  select(origin, arr_delay) %>% \n  slice(1:4)\n\norigin_dummies <- \n  recipe(arr_delay ~ origin, data = train_data) %>% \n  step_dummy(origin, keep_original_cols = TRUE) %>%\n  prep(training = four_origins)\n```\n\n```{r}\n#| label: \"dummy-table\"\n#| echo: false\n# Get a row for each factor level\nbake(origin_dummies, new_data = NULL, origin, starts_with(\"origin\")) %>% \n  distinct() %>% \n  knitr::kable() %>% \n  kable_styling(full_width = FALSE)\n```\n\nBut, unlike the standard model formula methods in R, a recipe **does not** automatically create these dummy variables for you; you'll need to tell your recipe to add this step. This is for two reasons. First, many models do not require [numeric predictors](https://bookdown.org/max/FES/categorical-trees.html), so dummy variables may not always be preferred. Second, recipes can also be used for purposes outside of modeling, where non-dummy versions of the variables may work better. For example, you may want to make a table or a plot with a variable as a single factor. For those reasons, you need to explicitly tell recipes to create dummy variables using `step_dummy()`:\n\n```{r}\n#| label: \"dummy\"\nflights_rec <- \n  recipe(arr_delay ~ ., data = train_data) %>% \n  update_role(flight, time_hour, new_role = \"ID\") %>% \n  step_date(date, features = c(\"dow\", \"month\")) %>%               \n  step_holiday(date, \n               holidays = timeDate::listHolidays(\"US\"), \n               keep_original_cols = FALSE) %>% \n  step_dummy(all_nominal_predictors())\n```\n\nHere, we did something different than before: instead of applying a step to an individual variable, we used [selectors](https://recipes.tidymodels.org/reference/selections.html) to apply this recipe step to several variables at once, `all_nominal_predictors()`. The [selector functions](https://recipes.tidymodels.org/reference/selections.html) can be combined to select intersections of variables.\n\nAt this stage in the recipe, this step selects the `origin`, `dest`, and `carrier` variables. It also includes two new variables, `date_dow` and `date_month`, that were created by the earlier `step_date()`.\n\nMore generally, the recipe selectors mean that you don't always have to apply steps to individual variables one at a time. Since a recipe knows the *variable type* and *role* of each column, they can also be selected (or dropped) using this information.\n\nWe need one final step to add to our recipe. Since `carrier` and `dest` have some infrequently occurring factor values, it is possible that dummy variables might be created for values that don't exist in the training set. For example, there is one destination that is only in the test set:\n\n```{r}\n#| label: \"zv-cols\"\ntest_data %>% \n  distinct(dest) %>% \n  anti_join(train_data)\n```\n\nWhen the recipe is applied to the training set, a column is made for `r dplyr::setdiff(test_data$dest, train_data$dest)` because the factor levels come from `flight_data` (not the training set), but this column will contain all zeros. This is a \"zero-variance predictor\" that has no information within the column. While some R functions will not produce an error for such predictors, it usually causes warnings and other issues. `step_zv()` will remove columns from the data when the training set data have a single value, so it is added to the recipe *after* `step_dummy()`:\n\n```{r}\n#| label: \"zv\"\nflights_rec <- \n  recipe(arr_delay ~ ., data = train_data) %>% \n  update_role(flight, time_hour, new_role = \"ID\") %>% \n  step_date(date, features = c(\"dow\", \"month\")) %>%               \n  step_holiday(date, \n               holidays = timeDate::listHolidays(\"US\"), \n               keep_original_cols = FALSE) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_zv(all_predictors())\n```\n\nNow we've created a *specification* of what should be done with the data. How do we use the recipe we made?\n\n## Fit a model with a recipe {#fit-workflow}\n\nLet's use logistic regression to model the flight data. As we saw in [*Build a Model*](/start/models/), we start by [building a model specification](/start/models/#build-model) using the parsnip package:\n\n```{r}\n#| label: \"model\"\nlr_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")\n```\n\nWe will want to use our recipe across several steps as we train and test our model. We will:\n\n1.  **Process the recipe using the training set**: This involves any estimation or calculations based on the training set. For our recipe, the training set will be used to determine which predictors should be converted to dummy variables and which predictors will have zero-variance in the training set, and should be slated for removal.\n\n2.  **Apply the recipe to the training set**: We create the final predictor set on the training set.\n\n3.  **Apply the recipe to the test set**: We create the final predictor set on the test set. Nothing is recomputed and no information from the test set is used here; the dummy variable and zero-variance results from the training set are applied to the test set.\n\nTo simplify this process, we can use a *model workflow*, which pairs a model and recipe together. This is a straightforward approach because different recipes are often needed for different models, so when a model and recipe are bundled, it becomes easier to train and test *workflows*. We'll use the [workflows package](https://workflows.tidymodels.org/) from tidymodels to bundle our parsnip model (`lr_mod`) with our recipe (`flights_rec`).\n\n```{r}\n#| label: \"workflow\"\nflights_wflow <- \n  workflow() %>% \n  add_model(lr_mod) %>% \n  add_recipe(flights_rec)\n\nflights_wflow\n```\n\nNow, there is a single function that can be used to prepare the recipe and train the model from the resulting predictors:\n\n```{r}\n#| label: \"fit\"\nflights_fit <- \n  flights_wflow %>% \n  fit(data = train_data)\n```\n\nThis object has the finalized recipe and fitted model objects inside. You may want to extract the model or recipe objects from the workflow. To do this, you can use the helper functions `extract_fit_parsnip()` and `extract_recipe()`. For example, here we pull the fitted model object then use the `broom::tidy()` function to get a tidy tibble of model coefficients:\n\n```{r}\n#| label: \"fit-glance\"\nflights_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()\n```\n\n## Use a trained workflow to predict {#predict-workflow}\n\nOur goal was to predict whether a plane arrives more than 30 minutes late. We have just:\n\n1.  Built the model (`lr_mod`),\n\n2.  Created a preprocessing recipe (`flights_rec`),\n\n3.  Bundled the model and recipe (`flights_wflow`), and\n\n4.  Trained our workflow using a single call to `fit()`.\n\nThe next step is to use the trained workflow (`flights_fit`) to predict with the unseen test data, which we will do with a single call to `predict()`. The `predict()` method applies the recipe to the new data, then passes them to the fitted model.\n\n```{r}\n#| label: \"pred-class\"\npredict(flights_fit, test_data)\n```\n\nBecause our outcome variable here is a factor, the output from `predict()` returns the predicted class: `late` versus `on_time`. But, let's say we want the predicted class probabilities for each flight instead. To return those, we can specify `type = \"prob\"` when we use `predict()` or use `augment()` with the model plus test data to save them together:\n\n```{r}\n#| label: \"test-pred\"\nflights_aug <- \n  augment(flights_fit, test_data)\n\n# The data look like: \nflights_aug %>%\n  select(arr_delay, time_hour, flight, .pred_class, .pred_on_time)\n```\n\nNow that we have a tibble with our predicted class probabilities, how will we evaluate the performance of our workflow? We can see from these first few rows that our model predicted these 5 on time flights correctly because the values of `.pred_on_time` are *p* \\> .50. But we also know that we have `r scales::comma(nrow(flights_aug))` rows total to predict. We would like to calculate a metric that tells how well our model predicted late arrivals, compared to the true status of our outcome variable, `arr_delay`.\n\nLet's use the area under the [ROC curve](https://bookdown.org/max/FES/measuring-performance.html#class-metrics) as our metric, computed using `roc_curve()` and `roc_auc()` from the [yardstick package](https://yardstick.tidymodels.org/).\n\nTo generate a ROC curve, we need the predicted class probabilities for `late` and `on_time`, which we just calculated in the code chunk above. We can create the ROC curve with these values, using `roc_curve()` and then piping to the `autoplot()` method:\n\n```{r}\n#| label: \"roc-plot\"\nflights_aug %>% \n  roc_curve(truth = arr_delay, .pred_late) %>% \n  autoplot()\n```\n\nSimilarly, `roc_auc()` estimates the area under the curve:\n\n```{r}\n#| label: \"roc-auc\"\nflights_aug %>% \n  roc_auc(truth = arr_delay, .pred_late)\n```\n\nNot too bad! We leave it to the reader to test out this workflow [*without*](https://workflows.tidymodels.org/reference/add_formula.html) this recipe. You can use `workflows::add_formula(arr_delay ~ .)` instead of `add_recipe()` (remember to remove the identification variables first!), and see whether our recipe improved our model's ability to predict late arrivals.\n\n```{r}\n#| eval: false\n#| include: false\nset.seed(555)\nflights_cens <- flight_data %>% \n  select(-flight, -time_hour)\n\nflights_cens_split <- initial_split(flights_cens, prop = 3/4)\nflights_cens_train <- training(flights_cens_split)\nflights_cens_test <- testing(flights_cens_split)\n\nflights_wflow_raw <-\n  workflow() %>% \n  add_model(lr_mod) %>% \n  add_formula(arr_delay ~ .)\n\nflights_fit_raw <- \n  flights_wflow_raw %>% \n  fit(data = flights_cens_train)\n\nflights_preds_raw <- \n  predict(flights_fit_raw, \n          flights_cens_test, \n          type = \"prob\") %>% \n  bind_cols(flights_cens_test %>% select(arr_delay)) \n\nflights_preds_raw %>% \n  roc_auc(truth = arr_delay, .pred_late)\n```\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n","srcMarkdownNoYaml":"\n\n```{r}\n#| label: \"setup\"\n#| include: false\n#| message: false\n#| warning: false\nsource(here::here(\"common.R\"))\n```\n\n```{r}\n#| label: \"load\"\n#| include: false\n#| message: false\n#| warning: false\nlibrary(tidymodels)\nlibrary(nycflights13)\nlibrary(kableExtra)\nlibrary(skimr)\npkgs <- c(\"tidymodels\", \"nycflights13\", \"skimr\")\n\ntheme_set(theme_bw() + theme(legend.position = \"top\"))\n```\n\n## Introduction {#intro}\n\nIn our [*Build a Model*](/start/models/) article, we learned how to specify and train models with different engines using the [parsnip package](https://parsnip.tidymodels.org/). In this article, we'll explore another tidymodels package, [recipes](https://recipes.tidymodels.org/), which is designed to help you preprocess your data *before* training your model. Recipes are built as a series of preprocessing steps, such as:\n\n-   converting qualitative predictors to indicator variables (also known as dummy variables),\n\n-   transforming data to be on a different scale (e.g., taking the logarithm of a variable),\n\n-   transforming whole groups of predictors together,\n\n-   extracting key features from raw variables (e.g., getting the day of the week out of a date variable),\n\nand so on. If you are familiar with R's formula interface, a lot of this might sound familiar and like what a formula already does. Recipes can be used to do many of the same things, but they have a much wider range of possibilities. This article shows how to use recipes for modeling.\n\n`r article_req_pkgs(pkgs)`\n\n```{r}\n#| eval: false\nlibrary(tidymodels)      # for the recipes package, along with the rest of tidymodels\n\n# Helper packages\nlibrary(nycflights13)    # for flight data\nlibrary(skimr)           # for variable summaries\n```\n\n{{< test-drive url=\"https://rstudio.cloud/project/2674862\" >}}\n\n## The New York City flight data {#data}\n\n```{r}\n#| label: \"flight-start\"\n#| echo: false\nset.seed(123)\n\nflight_data <- \n  flights %>% \n  mutate(\n    # Convert the arrival delay to a factor\n    arr_delay = ifelse(arr_delay >= 30, \"late\", \"on_time\"),\n    arr_delay = factor(arr_delay),\n    # We will use the date (not date-time) in the recipe below\n    date = lubridate::as_date(time_hour)\n  ) %>% \n  # Include the weather data\n  inner_join(weather, by = c(\"origin\", \"time_hour\")) %>% \n  # Only retain the specific columns we will use\n  select(dep_time, flight, origin, dest, air_time, distance, \n         carrier, date, arr_delay, time_hour) %>% \n  # Exclude missing data\n  na.omit() %>% \n  # For creating models, it is better to have qualitative columns\n  # encoded as factors (instead of character strings)\n  mutate_if(is.character, as.factor)\n```\n\nLet's use the [nycflights13 data](https://github.com/hadley/nycflights13) to predict whether a plane arrives more than 30 minutes late. This data set contains information on `r scales::comma(nrow(flight_data))` flights departing near New York City in 2013. Let's start by loading the data and making a few changes to the variables:\n\n```{r}\n#| ref.label: \"flight-start\"\n\n```\n\nWe can see that about `r percent(mean(flight_data$arr_delay == \"late\"))` of the flights in this data set arrived more than 30 minutes late.\n\n```{r}\n#| label: \"count-delays\"\nflight_data %>% \n  count(arr_delay) %>% \n  mutate(prop = n/sum(n))\n```\n\nBefore we start building up our recipe, let's take a quick look at a few specific variables that will be important for both preprocessing and modeling.\n\nFirst, notice that the variable we created called `arr_delay` is a factor variable; it is important that our outcome variable for training a logistic regression model is a factor.\n\n```{r}\n#| label: \"glimpse-flights\"\nglimpse(flight_data)\n```\n\nSecond, there are two variables that we don't want to use as predictors in our model, but that we would like to retain as identification variables that can be used to troubleshoot poorly predicted data points. These are `flight`, a numeric value, and `time_hour`, a date-time value.\n\nThird, there are `r length(levels(flight_data$dest))` flight destinations contained in `dest` and `r length(levels(flight_data$carrier))` distinct `carrier`s.\n\n```{r}\n#| label: \"skim-flights\"\nflight_data %>% \n  skimr::skim(dest, carrier) \n```\n\nBecause we'll be using a simple logistic regression model, the variables `dest` and `carrier` will be converted to [dummy variables](https://bookdown.org/max/FES/creating-dummy-variables-for-unordered-categories.html). However, some of these values do not occur very frequently and this could complicate our analysis. We'll discuss specific steps later in this article that we can add to our recipe to address this issue before modeling.\n\n## Data splitting {#data-split}\n\nTo get started, let's split this single dataset into two: a *training* set and a *testing* set. We'll keep most of the rows in the original dataset (subset chosen randomly) in the *training* set. The training data will be used to *fit* the model, and the *testing* set will be used to measure model performance.\n\nTo do this, we can use the [rsample](https://rsample.tidymodels.org/) package to create an object that contains the information on *how* to split the data, and then two more rsample functions to create data frames for the training and testing sets:\n\n```{r}\n#| label: \"split\"\n# Fix the random numbers by setting the seed \n# This enables the analysis to be reproducible when random numbers are used \nset.seed(222)\n# Put 3/4 of the data into the training set \ndata_split <- initial_split(flight_data, prop = 3/4)\n\n# Create data frames for the two sets:\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n```\n\n## Create recipe and roles {#recipe}\n\nTo get started, let's create a recipe for a simple logistic regression model. Before training the model, we can use a recipe to create a few new predictors and conduct some preprocessing required by the model.\n\nLet's initiate a new recipe:\n\n```{r}\n#| label: \"initial-recipe\"\nflights_rec <- \n  recipe(arr_delay ~ ., data = train_data) \n```\n\nThe [`recipe()` function](https://recipes.tidymodels.org/reference/recipe.html) as we used it here has two arguments:\n\n-   A **formula**. Any variable on the left-hand side of the tilde (`~`) is considered the model outcome (here, `arr_delay`). On the right-hand side of the tilde are the predictors. Variables may be listed by name, or you can use the dot (`.`) to indicate all other variables as predictors.\n\n-   The **data**. A recipe is associated with the data set used to create the model. This will typically be the *training* set, so `data = train_data` here. Naming a data set doesn't actually change the data itself; it is only used to catalog the names of the variables and their types, like factors, integers, dates, etc.\n\nNow we can add [roles](https://recipes.tidymodels.org/reference/roles.html) to this recipe. We can use the [`update_role()` function](https://recipes.tidymodels.org/reference/roles.html) to let recipes know that `flight` and `time_hour` are variables with a custom role that we called `\"ID\"` (a role can have any character value). Whereas our formula included all variables in the training set other than `arr_delay` as predictors, this tells the recipe to keep these two variables but not use them as either outcomes or predictors.\n\n```{r}\n#| label: \"recipe-roles\"\nflights_rec <- \n  recipe(arr_delay ~ ., data = train_data) %>% \n  update_role(flight, time_hour, new_role = \"ID\") \n```\n\nThis step of adding roles to a recipe is optional; the purpose of using it here is that those two variables can be retained in the data but not included in the model. This can be convenient when, after the model is fit, we want to investigate some poorly predicted value. These ID columns will be available and can be used to try to understand what went wrong.\n\nTo get the current set of variables and roles, use the `summary()` function:\n\n```{r}\n#| label: \"summary\"\nsummary(flights_rec)\n```\n\n## Create features {#features}\n\nNow we can start adding steps onto our recipe using the pipe operator. Perhaps it is reasonable for the date of the flight to have an effect on the likelihood of a late arrival. A little bit of **feature engineering** might go a long way to improving our model. How should the date be encoded into the model? The `date` column has an R `date` object so including that column \"as is\" will mean that the model will convert it to a numeric format equal to the number of days after a reference date:\n\n```{r}\n#| label: \"dates\"\nflight_data %>% \n  distinct(date) %>% \n  mutate(numeric_date = as.numeric(date)) \n```\n\nIt's possible that the numeric date variable is a good option for modeling; perhaps the model would benefit from a linear trend between the log-odds of a late arrival and the numeric date variable. However, it might be better to add model terms *derived* from the date that have a better potential to be important to the model. For example, we could derive the following meaningful features from the single `date` variable:\n\n-   the day of the week,\n\n-   the month, and\n\n-   whether or not the date corresponds to a holiday.\n\nLet's do all three of these by adding steps to our recipe:\n\n```{r}\n#| label: \"date-recipe\"\nflights_rec <- \n  recipe(arr_delay ~ ., data = train_data) %>% \n  update_role(flight, time_hour, new_role = \"ID\") %>% \n  step_date(date, features = c(\"dow\", \"month\")) %>%               \n  step_holiday(date, \n               holidays = timeDate::listHolidays(\"US\"), \n               keep_original_cols = FALSE)\n```\n\nWhat do each of these steps do?\n\n-   With [`step_date()`](https://recipes.tidymodels.org/reference/step_date.html), we created two new factor columns with the appropriate day of the week and the month.\n\n-   With [`step_holiday()`](https://recipes.tidymodels.org/reference/step_holiday.html), we created a binary variable indicating whether the current date is a holiday or not. The argument value of `timeDate::listHolidays(\"US\")` uses the [timeDate package](https://cran.r-project.org/web/packages/timeDate/index.html) to list the `r length(timeDate::listHolidays(\"US\"))` standard US holidays.\n\n-   With `keep_original_cols = FALSE`, we remove the original `date` variable since we no longer want it in the model. Many recipe steps that create new variables have this argument.\n\nNext, we'll turn our attention to the variable types of our predictors. Because we plan to train a logistic regression model, we know that predictors will ultimately need to be numeric, as opposed to nominal data like strings and factor variables. In other words, there may be a difference in how we store our data (in factors inside a data frame), and how the underlying equations require them (a purely numeric matrix).\n\nFor factors like `dest` and `origin`, [standard practice](https://bookdown.org/max/FES/creating-dummy-variables-for-unordered-categories.html) is to convert them into *dummy* or *indicator* variables to make them numeric. These are binary values for each level of the factor. For example, our `origin` variable has values of `\"EWR\"`, `\"JFK\"`, and `\"LGA\"`. The standard dummy variable encoding, shown below, will create *two* numeric columns of the data that are 1 when the originating airport is `\"JFK\"` or `\"LGA\"` and zero otherwise, respectively.\n\n```{r}\n#| label: \"calc-dummy\"\n#| include: false\nfour_origins <- \n  train_data %>% \n  select(origin, arr_delay) %>% \n  slice(1:4)\n\norigin_dummies <- \n  recipe(arr_delay ~ origin, data = train_data) %>% \n  step_dummy(origin, keep_original_cols = TRUE) %>%\n  prep(training = four_origins)\n```\n\n```{r}\n#| label: \"dummy-table\"\n#| echo: false\n# Get a row for each factor level\nbake(origin_dummies, new_data = NULL, origin, starts_with(\"origin\")) %>% \n  distinct() %>% \n  knitr::kable() %>% \n  kable_styling(full_width = FALSE)\n```\n\nBut, unlike the standard model formula methods in R, a recipe **does not** automatically create these dummy variables for you; you'll need to tell your recipe to add this step. This is for two reasons. First, many models do not require [numeric predictors](https://bookdown.org/max/FES/categorical-trees.html), so dummy variables may not always be preferred. Second, recipes can also be used for purposes outside of modeling, where non-dummy versions of the variables may work better. For example, you may want to make a table or a plot with a variable as a single factor. For those reasons, you need to explicitly tell recipes to create dummy variables using `step_dummy()`:\n\n```{r}\n#| label: \"dummy\"\nflights_rec <- \n  recipe(arr_delay ~ ., data = train_data) %>% \n  update_role(flight, time_hour, new_role = \"ID\") %>% \n  step_date(date, features = c(\"dow\", \"month\")) %>%               \n  step_holiday(date, \n               holidays = timeDate::listHolidays(\"US\"), \n               keep_original_cols = FALSE) %>% \n  step_dummy(all_nominal_predictors())\n```\n\nHere, we did something different than before: instead of applying a step to an individual variable, we used [selectors](https://recipes.tidymodels.org/reference/selections.html) to apply this recipe step to several variables at once, `all_nominal_predictors()`. The [selector functions](https://recipes.tidymodels.org/reference/selections.html) can be combined to select intersections of variables.\n\nAt this stage in the recipe, this step selects the `origin`, `dest`, and `carrier` variables. It also includes two new variables, `date_dow` and `date_month`, that were created by the earlier `step_date()`.\n\nMore generally, the recipe selectors mean that you don't always have to apply steps to individual variables one at a time. Since a recipe knows the *variable type* and *role* of each column, they can also be selected (or dropped) using this information.\n\nWe need one final step to add to our recipe. Since `carrier` and `dest` have some infrequently occurring factor values, it is possible that dummy variables might be created for values that don't exist in the training set. For example, there is one destination that is only in the test set:\n\n```{r}\n#| label: \"zv-cols\"\ntest_data %>% \n  distinct(dest) %>% \n  anti_join(train_data)\n```\n\nWhen the recipe is applied to the training set, a column is made for `r dplyr::setdiff(test_data$dest, train_data$dest)` because the factor levels come from `flight_data` (not the training set), but this column will contain all zeros. This is a \"zero-variance predictor\" that has no information within the column. While some R functions will not produce an error for such predictors, it usually causes warnings and other issues. `step_zv()` will remove columns from the data when the training set data have a single value, so it is added to the recipe *after* `step_dummy()`:\n\n```{r}\n#| label: \"zv\"\nflights_rec <- \n  recipe(arr_delay ~ ., data = train_data) %>% \n  update_role(flight, time_hour, new_role = \"ID\") %>% \n  step_date(date, features = c(\"dow\", \"month\")) %>%               \n  step_holiday(date, \n               holidays = timeDate::listHolidays(\"US\"), \n               keep_original_cols = FALSE) %>% \n  step_dummy(all_nominal_predictors()) %>% \n  step_zv(all_predictors())\n```\n\nNow we've created a *specification* of what should be done with the data. How do we use the recipe we made?\n\n## Fit a model with a recipe {#fit-workflow}\n\nLet's use logistic regression to model the flight data. As we saw in [*Build a Model*](/start/models/), we start by [building a model specification](/start/models/#build-model) using the parsnip package:\n\n```{r}\n#| label: \"model\"\nlr_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")\n```\n\nWe will want to use our recipe across several steps as we train and test our model. We will:\n\n1.  **Process the recipe using the training set**: This involves any estimation or calculations based on the training set. For our recipe, the training set will be used to determine which predictors should be converted to dummy variables and which predictors will have zero-variance in the training set, and should be slated for removal.\n\n2.  **Apply the recipe to the training set**: We create the final predictor set on the training set.\n\n3.  **Apply the recipe to the test set**: We create the final predictor set on the test set. Nothing is recomputed and no information from the test set is used here; the dummy variable and zero-variance results from the training set are applied to the test set.\n\nTo simplify this process, we can use a *model workflow*, which pairs a model and recipe together. This is a straightforward approach because different recipes are often needed for different models, so when a model and recipe are bundled, it becomes easier to train and test *workflows*. We'll use the [workflows package](https://workflows.tidymodels.org/) from tidymodels to bundle our parsnip model (`lr_mod`) with our recipe (`flights_rec`).\n\n```{r}\n#| label: \"workflow\"\nflights_wflow <- \n  workflow() %>% \n  add_model(lr_mod) %>% \n  add_recipe(flights_rec)\n\nflights_wflow\n```\n\nNow, there is a single function that can be used to prepare the recipe and train the model from the resulting predictors:\n\n```{r}\n#| label: \"fit\"\nflights_fit <- \n  flights_wflow %>% \n  fit(data = train_data)\n```\n\nThis object has the finalized recipe and fitted model objects inside. You may want to extract the model or recipe objects from the workflow. To do this, you can use the helper functions `extract_fit_parsnip()` and `extract_recipe()`. For example, here we pull the fitted model object then use the `broom::tidy()` function to get a tidy tibble of model coefficients:\n\n```{r}\n#| label: \"fit-glance\"\nflights_fit %>% \n  extract_fit_parsnip() %>% \n  tidy()\n```\n\n## Use a trained workflow to predict {#predict-workflow}\n\nOur goal was to predict whether a plane arrives more than 30 minutes late. We have just:\n\n1.  Built the model (`lr_mod`),\n\n2.  Created a preprocessing recipe (`flights_rec`),\n\n3.  Bundled the model and recipe (`flights_wflow`), and\n\n4.  Trained our workflow using a single call to `fit()`.\n\nThe next step is to use the trained workflow (`flights_fit`) to predict with the unseen test data, which we will do with a single call to `predict()`. The `predict()` method applies the recipe to the new data, then passes them to the fitted model.\n\n```{r}\n#| label: \"pred-class\"\npredict(flights_fit, test_data)\n```\n\nBecause our outcome variable here is a factor, the output from `predict()` returns the predicted class: `late` versus `on_time`. But, let's say we want the predicted class probabilities for each flight instead. To return those, we can specify `type = \"prob\"` when we use `predict()` or use `augment()` with the model plus test data to save them together:\n\n```{r}\n#| label: \"test-pred\"\nflights_aug <- \n  augment(flights_fit, test_data)\n\n# The data look like: \nflights_aug %>%\n  select(arr_delay, time_hour, flight, .pred_class, .pred_on_time)\n```\n\nNow that we have a tibble with our predicted class probabilities, how will we evaluate the performance of our workflow? We can see from these first few rows that our model predicted these 5 on time flights correctly because the values of `.pred_on_time` are *p* \\> .50. But we also know that we have `r scales::comma(nrow(flights_aug))` rows total to predict. We would like to calculate a metric that tells how well our model predicted late arrivals, compared to the true status of our outcome variable, `arr_delay`.\n\nLet's use the area under the [ROC curve](https://bookdown.org/max/FES/measuring-performance.html#class-metrics) as our metric, computed using `roc_curve()` and `roc_auc()` from the [yardstick package](https://yardstick.tidymodels.org/).\n\nTo generate a ROC curve, we need the predicted class probabilities for `late` and `on_time`, which we just calculated in the code chunk above. We can create the ROC curve with these values, using `roc_curve()` and then piping to the `autoplot()` method:\n\n```{r}\n#| label: \"roc-plot\"\nflights_aug %>% \n  roc_curve(truth = arr_delay, .pred_late) %>% \n  autoplot()\n```\n\nSimilarly, `roc_auc()` estimates the area under the curve:\n\n```{r}\n#| label: \"roc-auc\"\nflights_aug %>% \n  roc_auc(truth = arr_delay, .pred_late)\n```\n\nNot too bad! We leave it to the reader to test out this workflow [*without*](https://workflows.tidymodels.org/reference/add_formula.html) this recipe. You can use `workflows::add_formula(arr_delay ~ .)` instead of `add_recipe()` (remember to remove the identification variables first!), and see whether our recipe improved our model's ability to predict late arrivals.\n\n```{r}\n#| eval: false\n#| include: false\nset.seed(555)\nflights_cens <- flight_data %>% \n  select(-flight, -time_hour)\n\nflights_cens_split <- initial_split(flights_cens, prop = 3/4)\nflights_cens_train <- training(flights_cens_split)\nflights_cens_test <- testing(flights_cens_split)\n\nflights_wflow_raw <-\n  workflow() %>% \n  add_model(lr_mod) %>% \n  add_formula(arr_delay ~ .)\n\nflights_fit_raw <- \n  flights_wflow_raw %>% \n  fit(data = flights_cens_train)\n\nflights_preds_raw <- \n  predict(flights_fit_raw, \n          flights_cens_test, \n          type = \"prob\") %>% \n  bind_cols(flights_cens_test %>% select(arr_delay)) \n\nflights_preds_raw %>% \n  roc_auc(truth = arr_delay, .pred_late)\n```\n\n## Session information {#session-info}\n\n```{r}\n#| label: \"si\"\n#| echo: false\nsmall_session(pkgs)\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":2,"css":["../styles.css"],"include-after-body":["../repo-actions-delete.html"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","notebook-preview-download":"Download Notebook","notebook-preview-back":"Back to Article"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.92","theme":["cosmo","../../styles.scss","../../styles-frontpage.scss"],"quarto-required":">= 1.3.353","linestretch":1.6,"grid":{"body-width":"840px"},"title":"Preprocess your data with recipes","weight":2,"categories":["pre-processing","recipes","parsnip","workflows","yardstick","broom"],"description":"Prepare data for modeling with modular preprocessing steps.\n","toc-location":"body","toc-title":""},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}